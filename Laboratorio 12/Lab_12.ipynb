{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDZmp2BO9KnQ"
      },
      "source": [
        "# **Laboratorio 12: 🚀 Despliegue 🚀**\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>\n",
        "\n",
        "### **Cuerpo Docente:**\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebastián Tinoco\n",
        "- Auxiliar: Eduardo Moya\n",
        "- Ayudantes: Nicolás Ojeda, Melanie Peña, Valentina Rojas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdGqUgwX9pGQ"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados\n",
        "\n",
        "- Nombre de alumno 1: Francisca Ruiz\n",
        "- Nombre de alumno 2: Valentina Zúñiga\n",
        "\n",
        "### **Link de repositorio de GitHub:** [Repositorio](https://github.com/vazuniga1/Laboratorios)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YraSOKrf9yMl"
      },
      "source": [
        "## Temas a tratar\n",
        "\n",
        "- Entrenamiento y registro de modelos usando MLFlow.\n",
        "- Despliegue de modelo usando FastAPI\n",
        "- Containerización del proyecto usando Docker\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "\n",
        "- Generar una solución a un problema a partir de ML\n",
        "- Desplegar su solución usando MLFlow, FastAPI y Docker\n",
        "\n",
        "El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D98okEzUE8hb"
      },
      "source": [
        "# **Introducción**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSiuBfGiFlQM"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExODJnMHJzNzlkNmQweXoyY3ltbnZ2ZDlxY2c0aW5jcHNzeDNtOXBsdCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/AbPdhwsMgjMjax5reo/giphy.gif\" width=\"400\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPn8R-6u877j"
      },
      "source": [
        "\n",
        "\n",
        "Consumida en la tristeza el despido de Renacín, Smapina ha decaído en su desempeño, lo que se ha traducido en un irregular tratamiento del agua. Esto ha implicado una baja en la calidad del agua, llegando a haber algunos puntos de la comuna en la que el vital elemento no es apto para el consumo humano. Es por esto que la sanitaria pública de la municipalidad de Maipú se ha contactado con ustedes para que le entreguen una urgente solución a este problema (a la vez que dejan a Smapina, al igual que Renacín, sin trabajo 😔).\n",
        "\n",
        "El problema que la empresa le ha solicitado resolver es el de elaborar un sistema que les permita saber si el agua es potable o no. Para esto, la sanitaria les ha proveido una base de datos con la lectura de múltiples sensores IOT colocados en diversas cañerías, conductos y estanques. Estos sensores señalan nueve tipos de mediciones químicas y más una etiqueta elaborada en laboratorio que indica si el agua es potable o no el agua.\n",
        "\n",
        "La idea final es que puedan, en el caso que el agua no sea potable, dar un aviso inmediato para corregir el problema. Tenga en cuenta que parte del equipo docente vive en Maipú y su intoxicación podría implicar graves problemas para el cierre del curso.\n",
        "\n",
        "Atributos:\n",
        "\n",
        "1. pH value\n",
        "2. Hardness\n",
        "3. Solids (Total dissolved solids - TDS)\n",
        "4. Chloramines\n",
        "5. Sulfate\n",
        "6. Conductivity\n",
        "7. Organic_carbon\n",
        "8. Trihalomethanes\n",
        "9. Turbidity\n",
        "\n",
        "Variable a predecir:\n",
        "\n",
        "10. Potability (1 si es potable, 0 no potable)\n",
        "\n",
        "Descripción de cada atributo se pueden encontrar en el siguiente link: [dataset](https://www.kaggle.com/adityakadiwal/water-potability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aIr6KegWsjS"
      },
      "source": [
        "# **1. Optimización de modelos con Optuna + MLFlow (2.0 puntos)**\n",
        "\n",
        "El objetivo de esta sección es que ustedes puedan combinar Optuna con MLFlow para poder realizar la optimización de los hiperparámetros de sus modelos.\n",
        "\n",
        "Como aún no hemos hablado nada sobre `MLFlow` cabe preguntarse: **¡¿Qué !\"#@ es `MLflow`?!**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/eusgDKT4smQAAAAC/matthew-perry-chandler-bing.gif\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "## **MLFlow**\n",
        "\n",
        "`MLflow` es una plataforma de código abierto que simplifica la gestión y seguimiento de proyectos de aprendizaje automático. Con sus herramientas, los desarrolladores pueden organizar, rastrear y comparar experimentos, además de registrar modelos y controlar versiones.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://spark.apache.org/images/mlflow-logo.png\" width=\"350\">\n",
        "</p>\n",
        "\n",
        "Si bien esta plataforma cuenta con un gran número de herramientas y funcionalidades, en este laboratorio trabajaremos con dos:\n",
        "1. **Runs**: Registro que constituye la información guardada tras la ejecución de un entrenamiento. Cada `run` tiene su propio run_id, el cual sirve como identificador para el entrenamiento en sí mismo. Dentro de cada `run` podremos acceder a información como los hiperparámetros utilizados, las métricas obtenidas, las librerías requeridas y hasta nos permite descargar el modelo entrenado.\n",
        "2. **Experiments**: Se utilizan para agrupar y organizar diferentes ejecuciones de modelos (`runs`). En ese sentido, un experimento puede agrupar 1 o más `runs`. De esta manera, es posible también registrar métricas, parámetros y archivos (artefactos) asociados a cada experimento.\n",
        "\n",
        "### **Todo bien pero entonces, ¿cómo se usa en la práctica `MLflow`?**\n",
        "\n",
        "Es sencillo! Considerando un problema de machine learning genérico, podemos registrar la información relevante del entrenamiento ejecutando `mlflow.autolog()` antes entrenar nuestro modelo. Veamos este bonito ejemplo facilitado por los mismos creadores de `MLflow`:\n",
        "\n",
        "```python\n",
        "#!pip install mlflow\n",
        "import mlflow # importar mlflow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "db = load_diabetes()\n",
        "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
        "\n",
        "# Create and train models.\n",
        "rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
        "\n",
        "mlflow.autolog() # registrar automáticamente información del entrenamiento\n",
        "with mlflow.start_run(): # delimita inicio y fin del run\n",
        "    # aquí comienza el run\n",
        "    rf.fit(X_train, y_train) # train the model\n",
        "    predictions = rf.predict(X_test) # Use the model to make predictions on the test dataset.\n",
        "    # aquí termina el run\n",
        "```\n",
        "\n",
        "Si ustedes ejecutan el código anterior en sus máquinas locales (desde un jupyter notebook por ejemplo) se darán cuenta que en su directorio *root* se ha creado la carpeta `mlruns`. Esta carpeta lleva el tracking de todos los entrenamientos ejecutados desde el directorio root (importante: si se cambian de directorio y vuelven a ejecutar el código anterior, se creará otra carpeta y no tendrán acceso al entrenamiento anterior). Para visualizar estos entrenamientos, `MLflow` nos facilita hermosa interfaz visual a la que podemos acceder ejecutando:\n",
        "\n",
        "```\n",
        "mlflow ui\n",
        "```\n",
        "\n",
        "y luego pinchando en la ruta http://127.0.0.1:5000 que nos retorna la terminal. Veamos en vivo algunas de sus funcionalidades!\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExZXVuM3A5MW1heDFpa21qbGlwN2pyc2VoNnZsMmRzODZxdnluemo2bCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/3o84sq21TxDH6PyYms/giphy.gif\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Les dejamos también algunos comandos útiles:\n",
        "\n",
        "- `mlflow.create_experiment(\"nombre_experimento\")`: Les permite crear un nuevo experimento para agrupar entrenamientos\n",
        "- `mlflow.log_metric(\"nombre_métrica\", métrica)`: Les permite registrar una métrica *custom* bajo el nombre de \"nombre_métrica\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptP_ygr7S04t"
      },
      "source": [
        "## **1.1 Combinando Optuna + MLflow (2.0 puntos)**\n",
        "\n",
        "Ahora que tenemos conocimiento de ambas herramientas, intentemos ahora combinarlas para **más sabor**. El objetivo de este apartado es simple: automatizar la optimización de los parámetros de nuestros modelos usando `Optuna` y registrando de forma automática cada resultado en `MLFlow`.\n",
        "\n",
        "Considerando el objetivo planteado, se le pide completar la función `optimize_model`, la cual debe:\n",
        "- **Optimizar los hiperparámetros del modelo `XGBoost` usando `Optuna`.**\n",
        "- **Registrar cada entrenamiento en un experimento nuevo**, asegurándose de que la métrica `f1-score` se registre como `\"valid_f1\"`. No se deben guardar todos los experimentos en *Default*; en su lugar, cada `experiment` y `run` deben tener nombres interpretables, reconocibles y diferentes a los nombres por defecto (por ejemplo, para un run: \"XGBoost con lr 0.1\").\n",
        "- **Guardar los gráficos de Optuna** dentro de una carpeta de artefactos de Mlflow llamada `/plots`.\n",
        "- **Devolver el mejor modelo** usando la función `get_best_model` y serializarlo en el disco con `pickle.dump`. Luego, guardar el modelo en la carpeta `/models`.\n",
        "- **Guardar el código en `optimize.py`**. La ejecución de `python optimize.py` debería ejecutar la función `optimize_model`.\n",
        "- **Guardar las versiones de las librerías utilizadas** en el desarrollo.\n",
        "- **Respalde las configuraciones del modelo final y la importancia de las variables** en un gráfico dentro de la carpeta `/plots` creada anteriormente.\n",
        "\n",
        "*Hint: Le puede ser útil revisar los parámetros que recibe `mlflow.start_run`*\n",
        "\n",
        "```python\n",
        "def get_best_model(experiment_id):\n",
        "    runs = mlflow.search_runs(experiment_id)\n",
        "    best_model_id = runs.sort_values(\"metrics.valid_f1\")[\"run_id\"].iloc[0]\n",
        "    best_model = mlflow.sklearn.load_model(\"runs:/\" + best_model_id + \"/model\")\n",
        "\n",
        "    return best_model\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow\n",
        "!pip install -U kaleido\n",
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4-fcz_G83VB",
        "outputId": "522cd160-2768-4762-dfe8-49e3f4bf10f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting mlflow-skinny==2.18.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.18.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.0.3)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<19,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (17.0.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.36)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.0)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.18.0->mlflow)\n",
            "  Downloading databricks_sdk-0.38.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.43)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (8.5.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (4.25.5)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (0.5.2)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (2.27.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (4.0.11)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.18.0->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.2.15)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (0.49b2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (2024.8.30)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (5.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.6.1)\n",
            "Downloading mlflow-2.18.0-py3-none-any.whl (27.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.18.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m459.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.38.0-py3-none-any.whl (575 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.1/575.1 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, gunicorn, graphql-core, graphql-relay, docker, alembic, graphene, databricks-sdk, mlflow-skinny, mlflow\n",
            "Successfully installed Mako-1.3.6 alembic-1.14.0 databricks-sdk-0.38.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.5 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.18.0 mlflow-skinny-2.18.0\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\n",
            "Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kaleido\n",
            "Successfully installed kaleido-0.2.1\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.0)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.6)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.9.0 optuna-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import optuna\n",
        "import mlflow\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "qpB6uXym9lBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://docs.google.com/uc?export=download&id=1Ry2kgZGMKn76S976uHw4vTwvhnZlBGzq' -O water_potability.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQHJRWJC-CBH",
        "outputId": "dca1c6f4-a6ff-4837-a926-873cc4ca9563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-26 00:08:41--  https://docs.google.com/uc?export=download&id=1Ry2kgZGMKn76S976uHw4vTwvhnZlBGzq\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.202.113, 173.194.202.100, 173.194.202.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.202.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1Ry2kgZGMKn76S976uHw4vTwvhnZlBGzq&export=download [following]\n",
            "--2024-11-26 00:08:41--  https://drive.usercontent.google.com/download?id=1Ry2kgZGMKn76S976uHw4vTwvhnZlBGzq&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.199.132, 2607:f8b0:400e:c02::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.199.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 525187 (513K) [application/octet-stream]\n",
            "Saving to: ‘water_potability.csv’\n",
            "\n",
            "water_potability.cs 100%[===================>] 512.88K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-11-26 00:08:43 (50.1 MB/s) - ‘water_potability.csv’ saved [525187/525187]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_model(experiment_id):\n",
        "    runs = mlflow.search_runs(experiment_id)\n",
        "    best_model_id = runs.sort_values(\"metrics.valid_f1\")[\"run_id\"].iloc[0]\n",
        "    best_model = mlflow.sklearn.load_model(\"runs:/\" + best_model_id + \"/model\")\n",
        "\n",
        "    return best_model"
      ],
      "metadata": {
        "id": "AxjX28DAYWaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTNLPUnm8yzD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e277e5ac-48e6-4bf4-95a5-76a948324b77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Malformed experiment 'artifacts'. Detailed error Yaml file '/content/mlruns/artifacts/meta.yaml' does not exist.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mlflow/store/tracking/file_store.py\", line 328, in search_experiments\n",
            "    exp = self._get_experiment(exp_id, view_type)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mlflow/store/tracking/file_store.py\", line 422, in _get_experiment\n",
            "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mlflow/store/tracking/file_store.py\", line 1368, in _read_yaml\n",
            "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mlflow/store/tracking/file_store.py\", line 1361, in _read_helper\n",
            "    result = read_yaml(root, file_name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mlflow/utils/file_utils.py\", line 310, in read_yaml\n",
            "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
            "mlflow.exceptions.MissingConfigException: Yaml file '/content/mlruns/artifacts/meta.yaml' does not exist.\n",
            "[I 2024-11-26 00:12:42,800] A new study created in memory with name: no-name-e962eeb2-0568-4c35-b36c-fda850dbc55d\n",
            "[I 2024-11-26 00:12:44,468] Trial 0 finished with value: 0.6465731558526778 and parameters: {'eta': 0.06591387133728883, 'learning_rate': 0.04970622934962652, 'max_depth': 7, 'n_estimators': 289, 'subsample': 0.7779784325061259, 'colsample_bytree': 0.7147432068835436}. Best is trial 0 with value: 0.6465731558526778.\n",
            "[I 2024-11-26 00:12:47,642] Trial 1 finished with value: 0.6417664576266863 and parameters: {'eta': 0.04451823579090258, 'learning_rate': 0.019856857575886625, 'max_depth': 9, 'n_estimators': 473, 'subsample': 0.8939149651796247, 'colsample_bytree': 0.5331993792579294}. Best is trial 1 with value: 0.6417664576266863.\n",
            "[I 2024-11-26 00:12:49,466] Trial 2 finished with value: 0.6541184236154695 and parameters: {'eta': 0.07332516214589865, 'learning_rate': 0.03310691103835344, 'max_depth': 10, 'n_estimators': 150, 'subsample': 0.8688467307865491, 'colsample_bytree': 0.8962528071506255}. Best is trial 1 with value: 0.6417664576266863.\n",
            "[I 2024-11-26 00:12:50,039] Trial 3 finished with value: 0.6592245236952302 and parameters: {'eta': 0.053988393545629995, 'learning_rate': 0.03558917793490767, 'max_depth': 7, 'n_estimators': 149, 'subsample': 0.5751240644011406, 'colsample_bytree': 0.8022288861152809}. Best is trial 1 with value: 0.6417664576266863.\n",
            "[I 2024-11-26 00:12:50,881] Trial 4 finished with value: 0.6417664576266863 and parameters: {'eta': 0.09096057168200176, 'learning_rate': 0.028751590270071715, 'max_depth': 9, 'n_estimators': 124, 'subsample': 0.6871654758059549, 'colsample_bytree': 0.925824432105198}. Best is trial 1 with value: 0.6417664576266863.\n",
            "[I 2024-11-26 00:12:51,480] Trial 5 finished with value: 0.6171104630511296 and parameters: {'eta': 0.05170107309249185, 'learning_rate': 0.07056778744223217, 'max_depth': 5, 'n_estimators': 462, 'subsample': 0.6626101497205096, 'colsample_bytree': 0.5295927289218286}. Best is trial 5 with value: 0.6171104630511296.\n",
            "[I 2024-11-26 00:12:52,278] Trial 6 finished with value: 0.6590510248671865 and parameters: {'eta': 0.08169014421507903, 'learning_rate': 0.09848146173275676, 'max_depth': 5, 'n_estimators': 419, 'subsample': 0.5785174493324726, 'colsample_bytree': 0.7990434206099852}. Best is trial 5 with value: 0.6171104630511296.\n",
            "[I 2024-11-26 00:12:52,452] Trial 7 finished with value: 0.5893675850920045 and parameters: {'eta': 0.03947947594182752, 'learning_rate': 0.027012457849362494, 'max_depth': 3, 'n_estimators': 192, 'subsample': 0.7396119563962412, 'colsample_bytree': 0.5021790698744849}. Best is trial 7 with value: 0.5893675850920045.\n",
            "[I 2024-11-26 00:12:53,512] Trial 8 finished with value: 0.6302243329285242 and parameters: {'eta': 0.07361871044134276, 'learning_rate': 0.08043459740500689, 'max_depth': 8, 'n_estimators': 339, 'subsample': 0.6325509686342008, 'colsample_bytree': 0.6459261854132261}. Best is trial 7 with value: 0.5893675850920045.\n",
            "[I 2024-11-26 00:12:54,103] Trial 9 finished with value: 0.6588203729652069 and parameters: {'eta': 0.03138844995674508, 'learning_rate': 0.06955679455311199, 'max_depth': 8, 'n_estimators': 109, 'subsample': 0.8717615987084623, 'colsample_bytree': 0.9277879903583753}. Best is trial 7 with value: 0.5893675850920045.\n",
            "[I 2024-11-26 00:12:54,346] Trial 10 finished with value: 0.5781711566244583 and parameters: {'eta': 0.013080560311769268, 'learning_rate': 0.010587365642011015, 'max_depth': 3, 'n_estimators': 229, 'subsample': 0.7749403937313661, 'colsample_bytree': 0.6309727215598087}. Best is trial 10 with value: 0.5781711566244583.\n",
            "[I 2024-11-26 00:12:54,589] Trial 11 finished with value: 0.5875549546089205 and parameters: {'eta': 0.010216553540805223, 'learning_rate': 0.013730546356331037, 'max_depth': 3, 'n_estimators': 227, 'subsample': 0.7638681987881385, 'colsample_bytree': 0.6144365164277268}. Best is trial 10 with value: 0.5781711566244583.\n",
            "[I 2024-11-26 00:12:54,863] Trial 12 finished with value: 0.5886299587459651 and parameters: {'eta': 0.010128973082699317, 'learning_rate': 0.012613152317202787, 'max_depth': 3, 'n_estimators': 285, 'subsample': 0.9782645900145153, 'colsample_bytree': 0.621045350342341}. Best is trial 10 with value: 0.5781711566244583.\n",
            "[I 2024-11-26 00:12:55,186] Trial 13 finished with value: 0.5859415211769695 and parameters: {'eta': 0.01018246599883261, 'learning_rate': 0.010868457807495955, 'max_depth': 4, 'n_estimators': 209, 'subsample': 0.782786640899054, 'colsample_bytree': 0.6344849357421529}. Best is trial 10 with value: 0.5781711566244583.\n",
            "[I 2024-11-26 00:12:55,352] Trial 14 finished with value: 0.6065723816788643 and parameters: {'eta': 0.024523547723502504, 'learning_rate': 0.041934488477087625, 'max_depth': 5, 'n_estimators': 50, 'subsample': 0.8163413374641106, 'colsample_bytree': 0.7120086963436462}. Best is trial 10 with value: 0.5781711566244583.\n",
            "[I 2024-11-26 00:12:55,677] Trial 15 finished with value: 0.5777909972219465 and parameters: {'eta': 0.021859624396520613, 'learning_rate': 0.010322570290522283, 'max_depth': 4, 'n_estimators': 237, 'subsample': 0.9678408842638222, 'colsample_bytree': 0.660368408117236}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:12:56,141] Trial 16 finished with value: 0.6595456373583387 and parameters: {'eta': 0.023756169391514214, 'learning_rate': 0.053174147738202886, 'max_depth': 4, 'n_estimators': 346, 'subsample': 0.9738074502613852, 'colsample_bytree': 0.7686071834649546}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:12:56,685] Trial 17 finished with value: 0.6607411996038866 and parameters: {'eta': 0.02171535396483361, 'learning_rate': 0.04515929424626691, 'max_depth': 6, 'n_estimators': 250, 'subsample': 0.5244369136201844, 'colsample_bytree': 0.5780788845693666}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:12:57,153] Trial 18 finished with value: 0.6309449796178633 and parameters: {'eta': 0.03535118433915066, 'learning_rate': 0.024485082992387778, 'max_depth': 4, 'n_estimators': 354, 'subsample': 0.9306018263116727, 'colsample_bytree': 0.695529225124655}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:12:57,883] Trial 19 finished with value: 0.6533973569154499 and parameters: {'eta': 0.01989826873332518, 'learning_rate': 0.019563406296485734, 'max_depth': 6, 'n_estimators': 298, 'subsample': 0.8272892158978105, 'colsample_bytree': 0.6778412797266405}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:12:58,211] Trial 20 finished with value: 0.6475923561365161 and parameters: {'eta': 0.04506681972377786, 'learning_rate': 0.062013420756457875, 'max_depth': 4, 'n_estimators': 183, 'subsample': 0.7090895809889681, 'colsample_bytree': 0.8491558094443623}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:12:58,549] Trial 21 finished with value: 0.5827383935878468 and parameters: {'eta': 0.01536790791311962, 'learning_rate': 0.010285020819606642, 'max_depth': 4, 'n_estimators': 223, 'subsample': 0.8034316203667947, 'colsample_bytree': 0.5719782735230856}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:12:59,209] Trial 22 finished with value: 0.5777909972219465 and parameters: {'eta': 0.01713363056533223, 'learning_rate': 0.010400324224796895, 'max_depth': 3, 'n_estimators': 251, 'subsample': 0.8284329560808514, 'colsample_bytree': 0.5790154880363372}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:13:00,593] Trial 23 finished with value: 0.6098844833733488 and parameters: {'eta': 0.03005688168569396, 'learning_rate': 0.01877710742645755, 'max_depth': 3, 'n_estimators': 393, 'subsample': 0.9258151135505701, 'colsample_bytree': 0.583327131277677}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:13:01,285] Trial 24 finished with value: 0.6253242541793397 and parameters: {'eta': 0.03065393642766158, 'learning_rate': 0.03729145439994827, 'max_depth': 3, 'n_estimators': 260, 'subsample': 0.9980296247937032, 'colsample_bytree': 0.6541347481531176}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:13:02,080] Trial 25 finished with value: 0.6432528893129753 and parameters: {'eta': 0.017424079373461944, 'learning_rate': 0.022390234722009846, 'max_depth': 5, 'n_estimators': 315, 'subsample': 0.9363905534085897, 'colsample_bytree': 0.7391499790486491}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:13:02,368] Trial 26 finished with value: 0.6101031132262542 and parameters: {'eta': 0.028429460261989926, 'learning_rate': 0.028374012202121254, 'max_depth': 3, 'n_estimators': 255, 'subsample': 0.8478383938762959, 'colsample_bytree': 0.5999181395509164}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:13:02,681] Trial 27 finished with value: 0.603670496672318 and parameters: {'eta': 0.09905012056628257, 'learning_rate': 0.016338977624084143, 'max_depth': 4, 'n_estimators': 171, 'subsample': 0.7409640225541883, 'colsample_bytree': 0.992002325449552}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:13:02,917] Trial 28 finished with value: 0.6463827555228195 and parameters: {'eta': 0.03986684702012879, 'learning_rate': 0.09685586847002876, 'max_depth': 6, 'n_estimators': 93, 'subsample': 0.9061901752136654, 'colsample_bytree': 0.5494414855801976}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:13:03,452] Trial 29 finished with value: 0.6567992733058757 and parameters: {'eta': 0.0170363315255416, 'learning_rate': 0.04716532108911581, 'max_depth': 5, 'n_estimators': 314, 'subsample': 0.8354815225514514, 'colsample_bytree': 0.6630447396820418}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:13:03,711] Trial 30 finished with value: 0.6684599145615738 and parameters: {'eta': 0.062076157053214814, 'learning_rate': 0.08621442640691601, 'max_depth': 3, 'n_estimators': 234, 'subsample': 0.7127335155279625, 'colsample_bytree': 0.7344140822301171}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:13:04,015] Trial 31 finished with value: 0.5875549546089205 and parameters: {'eta': 0.015890663673584, 'learning_rate': 0.010825914516971642, 'max_depth': 4, 'n_estimators': 217, 'subsample': 0.7852091871326681, 'colsample_bytree': 0.5561701266801539}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:13:04,369] Trial 32 finished with value: 0.6017929522544211 and parameters: {'eta': 0.02383660022637609, 'learning_rate': 0.016288293310562717, 'max_depth': 4, 'n_estimators': 272, 'subsample': 0.8008465678342649, 'colsample_bytree': 0.5157652201739645}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:13:04,598] Trial 33 finished with value: 0.5779368752346831 and parameters: {'eta': 0.015719812245378266, 'learning_rate': 0.018949225711637287, 'max_depth': 3, 'n_estimators': 207, 'subsample': 0.8535761644877141, 'colsample_bytree': 0.5742273473499039}. Best is trial 15 with value: 0.5777909972219465.\n",
            "[I 2024-11-26 00:13:04,803] Trial 34 finished with value: 0.5768781434789292 and parameters: {'eta': 0.026755828989017343, 'learning_rate': 0.0227188976120671, 'max_depth': 3, 'n_estimators': 168, 'subsample': 0.8771138195944727, 'colsample_bytree': 0.5973340137304955}. Best is trial 34 with value: 0.5768781434789292.\n",
            "[I 2024-11-26 00:13:05,003] Trial 35 finished with value: 0.6157712922895358 and parameters: {'eta': 0.03619685092009585, 'learning_rate': 0.03355213800260537, 'max_depth': 3, 'n_estimators': 158, 'subsample': 0.869699450732603, 'colsample_bytree': 0.6017530194901153}. Best is trial 34 with value: 0.5768781434789292.\n",
            "[I 2024-11-26 00:13:05,738] Trial 36 finished with value: 0.6171309576083837 and parameters: {'eta': 0.04840732258111326, 'learning_rate': 0.02266205181242171, 'max_depth': 10, 'n_estimators': 133, 'subsample': 0.9001407689720385, 'colsample_bytree': 0.5390044641841049}. Best is trial 34 with value: 0.5768781434789292.\n",
            "[I 2024-11-26 00:13:05,960] Trial 37 finished with value: 0.618358127184867 and parameters: {'eta': 0.05846880932179749, 'learning_rate': 0.03239978911306779, 'max_depth': 3, 'n_estimators': 187, 'subsample': 0.9584612704732357, 'colsample_bytree': 0.6831509202376004}. Best is trial 34 with value: 0.5768781434789292.\n",
            "[I 2024-11-26 00:13:06,157] Trial 38 finished with value: 0.626636596322782 and parameters: {'eta': 0.026062324020718848, 'learning_rate': 0.04022820464233361, 'max_depth': 5, 'n_estimators': 81, 'subsample': 0.8552045391029872, 'colsample_bytree': 0.5931498797020884}. Best is trial 34 with value: 0.5768781434789292.\n",
            "[I 2024-11-26 00:13:06,481] Trial 39 finished with value: 0.619524912443216 and parameters: {'eta': 0.020432288568970943, 'learning_rate': 0.02688906290751788, 'max_depth': 4, 'n_estimators': 203, 'subsample': 0.8851226886523633, 'colsample_bytree': 0.5680715251271482}. Best is trial 34 with value: 0.5768781434789292.\n",
            "[I 2024-11-26 00:13:06,921] Trial 40 finished with value: 0.6216854740963035 and parameters: {'eta': 0.034203639081175616, 'learning_rate': 0.018127718427551544, 'max_depth': 7, 'n_estimators': 148, 'subsample': 0.9499827344436521, 'colsample_bytree': 0.5015683498463401}. Best is trial 34 with value: 0.5768781434789292.\n",
            "[I 2024-11-26 00:13:07,183] Trial 41 finished with value: 0.5832616729329348 and parameters: {'eta': 0.01426383709933395, 'learning_rate': 0.015687934190902426, 'max_depth': 3, 'n_estimators': 244, 'subsample': 0.9109271988356391, 'colsample_bytree': 0.629829862950605}. Best is trial 34 with value: 0.5768781434789292.\n",
            "[I 2024-11-26 00:13:07,497] Trial 42 finished with value: 0.621786911164848 and parameters: {'eta': 0.014297350363994635, 'learning_rate': 0.02229386702406902, 'max_depth': 3, 'n_estimators': 275, 'subsample': 0.7635988645738931, 'colsample_bytree': 0.6514426501928722}. Best is trial 34 with value: 0.5768781434789292.\n",
            "[I 2024-11-26 00:13:07,685] Trial 43 finished with value: 0.5882734226871835 and parameters: {'eta': 0.020419515338557057, 'learning_rate': 0.03048547458265941, 'max_depth': 3, 'n_estimators': 173, 'subsample': 0.8474407238294467, 'colsample_bytree': 0.5324730824066696}. Best is trial 34 with value: 0.5768781434789292.\n",
            "[I 2024-11-26 00:13:07,917] Trial 44 finished with value: 0.5773595466568135 and parameters: {'eta': 0.02717848455709386, 'learning_rate': 0.0142042744191886, 'max_depth': 3, 'n_estimators': 209, 'subsample': 0.8787190236742433, 'colsample_bytree': 0.6170311531064416}. Best is trial 34 with value: 0.5768781434789292.\n",
            "[I 2024-11-26 00:13:08,783] Trial 45 finished with value: 0.650947732397509 and parameters: {'eta': 0.04149217627243298, 'learning_rate': 0.014927590553565323, 'max_depth': 8, 'n_estimators': 199, 'subsample': 0.8868752519860301, 'colsample_bytree': 0.6082173753620652}. Best is trial 34 with value: 0.5768781434789292.\n",
            "[I 2024-11-26 00:13:08,986] Trial 46 finished with value: 0.5854070190358391 and parameters: {'eta': 0.0768756385660926, 'learning_rate': 0.0244016492859037, 'max_depth': 4, 'n_estimators': 130, 'subsample': 0.8739047780836183, 'colsample_bytree': 0.5487880259040931}. Best is trial 34 with value: 0.5768781434789292.\n",
            "[I 2024-11-26 00:13:09,988] Trial 47 finished with value: 0.6339016130660492 and parameters: {'eta': 0.02648928692360645, 'learning_rate': 0.020898415084671093, 'max_depth': 9, 'n_estimators': 159, 'subsample': 0.9993071949123736, 'colsample_bytree': 0.7818606552814844}. Best is trial 34 with value: 0.5768781434789292.\n",
            "[I 2024-11-26 00:13:10,405] Trial 48 finished with value: 0.6156303174717939 and parameters: {'eta': 0.03320708341741559, 'learning_rate': 0.01358894185531484, 'max_depth': 3, 'n_estimators': 481, 'subsample': 0.810124694451958, 'colsample_bytree': 0.6249340652841255}. Best is trial 34 with value: 0.5768781434789292.\n",
            "[I 2024-11-26 00:13:10,740] Trial 49 finished with value: 0.6334951190173846 and parameters: {'eta': 0.02866628828978058, 'learning_rate': 0.027502998499031654, 'max_depth': 4, 'n_estimators': 208, 'subsample': 0.9211217590758636, 'colsample_bytree': 0.7135768563855711}. Best is trial 34 with value: 0.5768781434789292.\n",
            "[I 2024-11-26 00:13:11,057] Trial 50 finished with value: 0.662584342001371 and parameters: {'eta': 0.01888105550020413, 'learning_rate': 0.060140955024305, 'max_depth': 3, 'n_estimators': 302, 'subsample': 0.8301511985263821, 'colsample_bytree': 0.6677327367670097}. Best is trial 34 with value: 0.5768781434789292.\n",
            "[I 2024-11-26 00:13:11,307] Trial 51 finished with value: 0.5705362454321408 and parameters: {'eta': 0.012819006115905843, 'learning_rate': 0.01048231792091098, 'max_depth': 3, 'n_estimators': 236, 'subsample': 0.7641614209422443, 'colsample_bytree': 0.6352726862401226}. Best is trial 51 with value: 0.5705362454321408.\n",
            "[I 2024-11-26 00:13:11,598] Trial 52 finished with value: 0.5705362454321408 and parameters: {'eta': 0.013101387263583909, 'learning_rate': 0.010168741476136358, 'max_depth': 3, 'n_estimators': 234, 'subsample': 0.6287795245609077, 'colsample_bytree': 0.6381799363675827}. Best is trial 51 with value: 0.5705362454321408.\n",
            "[I 2024-11-26 00:13:12,118] Trial 53 finished with value: 0.5875549546089205 and parameters: {'eta': 0.01159859050997905, 'learning_rate': 0.013998354404255859, 'max_depth': 3, 'n_estimators': 239, 'subsample': 0.5995572771698665, 'colsample_bytree': 0.638986121355901}. Best is trial 51 with value: 0.5705362454321408.\n",
            "[I 2024-11-26 00:13:13,741] Trial 54 finished with value: 0.5911481126115464 and parameters: {'eta': 0.022132859820785545, 'learning_rate': 0.010276906886984058, 'max_depth': 4, 'n_estimators': 269, 'subsample': 0.6450479102241189, 'colsample_bytree': 0.6129253622085112}. Best is trial 51 with value: 0.5705362454321408.\n",
            "[I 2024-11-26 00:13:14,821] Trial 55 finished with value: 0.6093406973559705 and parameters: {'eta': 0.01198672443364633, 'learning_rate': 0.012970879655043996, 'max_depth': 4, 'n_estimators': 227, 'subsample': 0.536875534708505, 'colsample_bytree': 0.6985910610175879}. Best is trial 51 with value: 0.5705362454321408.\n",
            "[I 2024-11-26 00:13:15,107] Trial 56 finished with value: 0.6023209850826585 and parameters: {'eta': 0.026236303823234115, 'learning_rate': 0.01747550291797861, 'max_depth': 3, 'n_estimators': 255, 'subsample': 0.6755073170922039, 'colsample_bytree': 0.6925319367603618}. Best is trial 51 with value: 0.5705362454321408.\n",
            "[I 2024-11-26 00:13:15,397] Trial 57 finished with value: 0.5859415211769695 and parameters: {'eta': 0.022687455258066456, 'learning_rate': 0.01015757997644128, 'max_depth': 3, 'n_estimators': 287, 'subsample': 0.6099100125728804, 'colsample_bytree': 0.5864758469698125}. Best is trial 51 with value: 0.5705362454321408.\n",
            "[I 2024-11-26 00:13:15,835] Trial 58 finished with value: 0.6391096759583982 and parameters: {'eta': 0.036888710490036065, 'learning_rate': 0.020282686269833657, 'max_depth': 5, 'n_estimators': 189, 'subsample': 0.7134148416070748, 'colsample_bytree': 0.8270752376287642}. Best is trial 51 with value: 0.5705362454321408.\n",
            "[I 2024-11-26 00:13:16,255] Trial 59 finished with value: 0.6254283561729005 and parameters: {'eta': 0.01938554291845396, 'learning_rate': 0.014085761629247785, 'max_depth': 4, 'n_estimators': 331, 'subsample': 0.7556678228821918, 'colsample_bytree': 0.6495126761339847}. Best is trial 51 with value: 0.5705362454321408.\n",
            "[I 2024-11-26 00:13:16,435] Trial 60 finished with value: 0.5854070190358391 and parameters: {'eta': 0.010489521051229491, 'learning_rate': 0.025274471183105097, 'max_depth': 3, 'n_estimators': 112, 'subsample': 0.7826852178411435, 'colsample_bytree': 0.6275711103620487}. Best is trial 51 with value: 0.5705362454321408.\n",
            "[I 2024-11-26 00:13:16,668] Trial 61 finished with value: 0.584825625188912 and parameters: {'eta': 0.017205634164585544, 'learning_rate': 0.018748152495981017, 'max_depth': 3, 'n_estimators': 209, 'subsample': 0.8572743843684806, 'colsample_bytree': 0.5675331166878963}. Best is trial 51 with value: 0.5705362454321408.\n",
            "[I 2024-11-26 00:13:16,908] Trial 62 finished with value: 0.5854070190358391 and parameters: {'eta': 0.01393955376299851, 'learning_rate': 0.016760516638187527, 'max_depth': 3, 'n_estimators': 172, 'subsample': 0.7333030538346484, 'colsample_bytree': 0.5954916937684945}. Best is trial 51 with value: 0.5705362454321408.\n",
            "[I 2024-11-26 00:13:17,152] Trial 63 finished with value: 0.5687584137154342 and parameters: {'eta': 0.017056573482758138, 'learning_rate': 0.01342439091226814, 'max_depth': 3, 'n_estimators': 240, 'subsample': 0.8211748151152303, 'colsample_bytree': 0.5211081795135114}. Best is trial 63 with value: 0.5687584137154342.\n",
            "[I 2024-11-26 00:13:17,408] Trial 64 finished with value: 0.5715636999334047 and parameters: {'eta': 0.031282417622418866, 'learning_rate': 0.012984506176960266, 'max_depth': 3, 'n_estimators': 244, 'subsample': 0.793808343202755, 'colsample_bytree': 0.5145807607415062}. Best is trial 63 with value: 0.5687584137154342.\n",
            "[I 2024-11-26 00:13:17,689] Trial 65 finished with value: 0.589142090936417 and parameters: {'eta': 0.028305248913035427, 'learning_rate': 0.013055822471824744, 'max_depth': 4, 'n_estimators': 225, 'subsample': 0.7959797177873428, 'colsample_bytree': 0.5228896273114751}. Best is trial 63 with value: 0.5687584137154342.\n",
            "[I 2024-11-26 00:13:17,963] Trial 66 finished with value: 0.576086618459869 and parameters: {'eta': 0.031814057615900206, 'learning_rate': 0.012990882987113941, 'max_depth': 3, 'n_estimators': 238, 'subsample': 0.5516733177161348, 'colsample_bytree': 0.5223323957645651}. Best is trial 63 with value: 0.5687584137154342.\n",
            "[I 2024-11-26 00:13:18,221] Trial 67 finished with value: 0.6040242622399234 and parameters: {'eta': 0.0430047559460609, 'learning_rate': 0.021927533638114657, 'max_depth': 3, 'n_estimators': 278, 'subsample': 0.5491156660395782, 'colsample_bytree': 0.5135791871952445}. Best is trial 63 with value: 0.5687584137154342.\n",
            "[I 2024-11-26 00:13:18,555] Trial 68 finished with value: 0.597321876937034 and parameters: {'eta': 0.06708297336475898, 'learning_rate': 0.01560578079935415, 'max_depth': 4, 'n_estimators': 264, 'subsample': 0.5747239592679771, 'colsample_bytree': 0.5527153209246053}. Best is trial 63 with value: 0.5687584137154342.\n",
            "[I 2024-11-26 00:13:18,790] Trial 69 finished with value: 0.6430467437824686 and parameters: {'eta': 0.032766734923975006, 'learning_rate': 0.07178458591739369, 'max_depth': 3, 'n_estimators': 241, 'subsample': 0.5150296509026149, 'colsample_bytree': 0.5096896178317379}. Best is trial 63 with value: 0.5687584137154342.\n",
            "[I 2024-11-26 00:13:19,128] Trial 70 finished with value: 0.6171309576083837 and parameters: {'eta': 0.038400177726729316, 'learning_rate': 0.024034584157900423, 'max_depth': 3, 'n_estimators': 370, 'subsample': 0.6908358841472715, 'colsample_bytree': 0.5324555802970907}. Best is trial 63 with value: 0.5687584137154342.\n",
            "[I 2024-11-26 00:13:19,374] Trial 71 finished with value: 0.5805221988561545 and parameters: {'eta': 0.03060260979996984, 'learning_rate': 0.012344650570759843, 'max_depth': 3, 'n_estimators': 221, 'subsample': 0.8198227511457618, 'colsample_bytree': 0.6649636671727193}. Best is trial 63 with value: 0.5687584137154342.\n",
            "[I 2024-11-26 00:13:19,780] Trial 72 finished with value: 0.6059362488546345 and parameters: {'eta': 0.024878743770782735, 'learning_rate': 0.012554550074613847, 'max_depth': 3, 'n_estimators': 451, 'subsample': 0.7747288326927682, 'colsample_bytree': 0.5618873978248267}. Best is trial 63 with value: 0.5687584137154342.\n",
            "[I 2024-11-26 00:13:20,101] Trial 73 finished with value: 0.5928615102179267 and parameters: {'eta': 0.02251304821375328, 'learning_rate': 0.01961319643185954, 'max_depth': 4, 'n_estimators': 236, 'subsample': 0.5594435671659526, 'colsample_bytree': 0.5425175996405005}. Best is trial 63 with value: 0.5687584137154342.\n",
            "[I 2024-11-26 00:13:20,314] Trial 74 finished with value: 0.5729640402769862 and parameters: {'eta': 0.04795217534835691, 'learning_rate': 0.016244098317254953, 'max_depth': 3, 'n_estimators': 196, 'subsample': 0.506196688027279, 'colsample_bytree': 0.5243682903847714}. Best is trial 63 with value: 0.5687584137154342.\n",
            "[I 2024-11-26 00:13:20,533] Trial 75 finished with value: 0.568482790988297 and parameters: {'eta': 0.052348657349086516, 'learning_rate': 0.016370659492023633, 'max_depth': 3, 'n_estimators': 192, 'subsample': 0.6136514582601824, 'colsample_bytree': 0.5229813241619791}. Best is trial 75 with value: 0.568482790988297.\n",
            "[I 2024-11-26 00:13:20,734] Trial 76 finished with value: 0.5661183588580072 and parameters: {'eta': 0.05233836912619443, 'learning_rate': 0.017165330844961527, 'max_depth': 3, 'n_estimators': 178, 'subsample': 0.5165210097403664, 'colsample_bytree': 0.5226272680277123}. Best is trial 76 with value: 0.5661183588580072.\n",
            "[I 2024-11-26 00:13:20,986] Trial 77 finished with value: 0.576086618459869 and parameters: {'eta': 0.05201587105109848, 'learning_rate': 0.017293641142906047, 'max_depth': 3, 'n_estimators': 195, 'subsample': 0.5050219386454893, 'colsample_bytree': 0.5235458248671944}. Best is trial 76 with value: 0.5661183588580072.\n",
            "[I 2024-11-26 00:13:21,204] Trial 78 finished with value: 0.6038621202247934 and parameters: {'eta': 0.05292398583206724, 'learning_rate': 0.031116325599536546, 'max_depth': 4, 'n_estimators': 143, 'subsample': 0.5342209298932391, 'colsample_bytree': 0.501876552029879}. Best is trial 76 with value: 0.5661183588580072.\n",
            "[I 2024-11-26 00:13:21,426] Trial 79 finished with value: 0.6110975172293412 and parameters: {'eta': 0.05849937491726522, 'learning_rate': 0.05248515903349149, 'max_depth': 3, 'n_estimators': 184, 'subsample': 0.5951990199503224, 'colsample_bytree': 0.5227568449446574}. Best is trial 76 with value: 0.5661183588580072.\n",
            "[I 2024-11-26 00:13:21,672] Trial 80 finished with value: 0.6215277898951547 and parameters: {'eta': 0.0484062798756712, 'learning_rate': 0.03601565407440574, 'max_depth': 3, 'n_estimators': 251, 'subsample': 0.629188409593357, 'colsample_bytree': 0.5355966197508217}. Best is trial 76 with value: 0.5661183588580072.\n",
            "[I 2024-11-26 00:13:21,896] Trial 81 finished with value: 0.5712509813538651 and parameters: {'eta': 0.049889822824394386, 'learning_rate': 0.016965064666576542, 'max_depth': 3, 'n_estimators': 197, 'subsample': 0.5116104700850069, 'colsample_bytree': 0.524076257216928}. Best is trial 76 with value: 0.5661183588580072.\n",
            "[I 2024-11-26 00:13:22,137] Trial 82 finished with value: 0.5859415211769695 and parameters: {'eta': 0.04854647753939017, 'learning_rate': 0.016759264443963372, 'max_depth': 3, 'n_estimators': 216, 'subsample': 0.5159703099742099, 'colsample_bytree': 0.5107685356954808}. Best is trial 76 with value: 0.5661183588580072.\n",
            "[I 2024-11-26 00:13:22,355] Trial 83 finished with value: 0.5784131851983689 and parameters: {'eta': 0.056673740278008804, 'learning_rate': 0.020188999321656735, 'max_depth': 3, 'n_estimators': 181, 'subsample': 0.5014898864724051, 'colsample_bytree': 0.5426988447745396}. Best is trial 76 with value: 0.5661183588580072.\n",
            "[I 2024-11-26 00:13:22,583] Trial 84 finished with value: 0.5564653201487503 and parameters: {'eta': 0.04585737375183139, 'learning_rate': 0.011674675447739098, 'max_depth': 3, 'n_estimators': 196, 'subsample': 0.5590991513543984, 'colsample_bytree': 0.5555279395625857}. Best is trial 84 with value: 0.5564653201487503.\n",
            "[I 2024-11-26 00:13:22,813] Trial 85 finished with value: 0.5867893787596538 and parameters: {'eta': 0.045512185243545514, 'learning_rate': 0.025600878594197542, 'max_depth': 4, 'n_estimators': 157, 'subsample': 0.57886596232487, 'colsample_bytree': 0.5466891533748038}. Best is trial 84 with value: 0.5564653201487503.\n",
            "[I 2024-11-26 00:13:23,083] Trial 86 finished with value: 0.5886299587459651 and parameters: {'eta': 0.06176396838575165, 'learning_rate': 0.015428764840490378, 'max_depth': 3, 'n_estimators': 198, 'subsample': 0.5337841983918578, 'colsample_bytree': 0.5561601778643732}. Best is trial 84 with value: 0.5564653201487503.\n",
            "[I 2024-11-26 00:13:23,317] Trial 87 finished with value: 0.5748895166558387 and parameters: {'eta': 0.05530054912662369, 'learning_rate': 0.01172678367820638, 'max_depth': 3, 'n_estimators': 218, 'subsample': 0.5671613610601683, 'colsample_bytree': 0.5017234035187901}. Best is trial 84 with value: 0.5564653201487503.\n",
            "[I 2024-11-26 00:13:23,578] Trial 88 finished with value: 0.6171309576083837 and parameters: {'eta': 0.046023210162819225, 'learning_rate': 0.021168430600465873, 'max_depth': 4, 'n_estimators': 164, 'subsample': 0.526247956246609, 'colsample_bytree': 0.5794368802202722}. Best is trial 84 with value: 0.5564653201487503.\n",
            "[I 2024-11-26 00:13:23,796] Trial 89 finished with value: 0.5854070190358391 and parameters: {'eta': 0.049849890081553265, 'learning_rate': 0.018350338578834377, 'max_depth': 3, 'n_estimators': 178, 'subsample': 0.5908120908556055, 'colsample_bytree': 0.5611653130644817}. Best is trial 84 with value: 0.5564653201487503.\n",
            "[I 2024-11-26 00:13:24,320] Trial 90 finished with value: 0.6326540441671008 and parameters: {'eta': 0.04278501654240959, 'learning_rate': 0.02922153559666255, 'max_depth': 7, 'n_estimators': 193, 'subsample': 0.5464181088700875, 'colsample_bytree': 0.5339248097902074}. Best is trial 84 with value: 0.5564653201487503.\n",
            "[I 2024-11-26 00:13:24,550] Trial 91 finished with value: 0.5691395929812383 and parameters: {'eta': 0.05391626316427364, 'learning_rate': 0.011557620700478803, 'max_depth': 3, 'n_estimators': 217, 'subsample': 0.577411292429345, 'colsample_bytree': 0.500617710400584}. Best is trial 84 with value: 0.5564653201487503.\n",
            "[I 2024-11-26 00:13:24,790] Trial 92 finished with value: 0.5633236331135995 and parameters: {'eta': 0.054569002736098424, 'learning_rate': 0.011791769794350763, 'max_depth': 3, 'n_estimators': 213, 'subsample': 0.5197874278058113, 'colsample_bytree': 0.5117595161312806}. Best is trial 84 with value: 0.5564653201487503.\n",
            "[I 2024-11-26 00:13:25,403] Trial 93 finished with value: 0.5642413087504239 and parameters: {'eta': 0.05470001806803741, 'learning_rate': 0.010196526670955547, 'max_depth': 3, 'n_estimators': 232, 'subsample': 0.6123195528660338, 'colsample_bytree': 0.514513957162034}. Best is trial 84 with value: 0.5564653201487503.\n",
            "[I 2024-11-26 00:13:26,321] Trial 94 finished with value: 0.562332215566574 and parameters: {'eta': 0.061052450938160925, 'learning_rate': 0.010110337075746685, 'max_depth': 3, 'n_estimators': 215, 'subsample': 0.6201883265762467, 'colsample_bytree': 0.5353417676098846}. Best is trial 84 with value: 0.5564653201487503.\n",
            "[I 2024-11-26 00:13:26,891] Trial 95 finished with value: 0.5594072531415242 and parameters: {'eta': 0.06244210289899973, 'learning_rate': 0.010080724741081947, 'max_depth': 3, 'n_estimators': 230, 'subsample': 0.6142102377288303, 'colsample_bytree': 0.5021742139946384}. Best is trial 84 with value: 0.5564653201487503.\n",
            "[I 2024-11-26 00:13:27,443] Trial 96 finished with value: 0.5613412145736589 and parameters: {'eta': 0.06791759490940266, 'learning_rate': 0.011435563267469863, 'max_depth': 3, 'n_estimators': 213, 'subsample': 0.6496915962171611, 'colsample_bytree': 0.5019072676982165}. Best is trial 84 with value: 0.5564653201487503.\n",
            "[I 2024-11-26 00:13:28,289] Trial 97 finished with value: 0.5743537010282995 and parameters: {'eta': 0.06761543941456043, 'learning_rate': 0.011807496221251407, 'max_depth': 4, 'n_estimators': 211, 'subsample': 0.6556245898787461, 'colsample_bytree': 0.5129508414285318}. Best is trial 84 with value: 0.5564653201487503.\n",
            "[I 2024-11-26 00:13:28,554] Trial 98 finished with value: 0.584334035223794 and parameters: {'eta': 0.07137383945686596, 'learning_rate': 0.014698600686560606, 'max_depth': 3, 'n_estimators': 259, 'subsample': 0.6170574982996604, 'colsample_bytree': 0.5046973668386641}. Best is trial 84 with value: 0.5564653201487503.\n",
            "[I 2024-11-26 00:13:29,016] Trial 99 finished with value: 0.606135640053045 and parameters: {'eta': 0.06080116143297901, 'learning_rate': 0.014698380737634593, 'max_depth': 6, 'n_estimators': 226, 'subsample': 0.6140185170477678, 'colsample_bytree': 0.5012408544535556}. Best is trial 84 with value: 0.5564653201487503.\n",
            "[I 2024-11-26 00:13:29,331] Trial 100 finished with value: 0.5944243066936598 and parameters: {'eta': 0.06524240079451751, 'learning_rate': 0.011596987350445226, 'max_depth': 4, 'n_estimators': 140, 'subsample': 0.646961891374083, 'colsample_bytree': 0.9166224549398851}. Best is trial 84 with value: 0.5564653201487503.\n",
            "[I 2024-11-26 00:13:29,569] Trial 101 finished with value: 0.5671249416175891 and parameters: {'eta': 0.06455178863785796, 'learning_rate': 0.011411267000654776, 'max_depth': 3, 'n_estimators': 218, 'subsample': 0.5878730841858479, 'colsample_bytree': 0.5385580072016505}. Best is trial 84 with value: 0.5564653201487503.\n",
            "[I 2024-11-26 00:13:29,789] Trial 102 finished with value: 0.5524451796021478 and parameters: {'eta': 0.0647830288117615, 'learning_rate': 0.010039706793595034, 'max_depth': 3, 'n_estimators': 205, 'subsample': 0.5808026680954473, 'colsample_bytree': 0.533031866280084}. Best is trial 102 with value: 0.5524451796021478.\n",
            "[I 2024-11-26 00:13:30,019] Trial 103 finished with value: 0.5712509813538651 and parameters: {'eta': 0.06329345463779176, 'learning_rate': 0.014789288304357145, 'max_depth': 3, 'n_estimators': 206, 'subsample': 0.6026632475644749, 'colsample_bytree': 0.5395225176623812}. Best is trial 102 with value: 0.5524451796021478.\n",
            "[I 2024-11-26 00:13:30,225] Trial 104 finished with value: 0.5402893630569452 and parameters: {'eta': 0.07161883712947323, 'learning_rate': 0.010351046349688262, 'max_depth': 3, 'n_estimators': 186, 'subsample': 0.587288463417052, 'colsample_bytree': 0.5504431462850661}. Best is trial 104 with value: 0.5402893630569452.\n",
            "[I 2024-11-26 00:13:30,479] Trial 105 finished with value: 0.5832616729329348 and parameters: {'eta': 0.07086707007527833, 'learning_rate': 0.01875217200749304, 'max_depth': 3, 'n_estimators': 179, 'subsample': 0.5894009942753025, 'colsample_bytree': 0.5696381753072763}. Best is trial 104 with value: 0.5402893630569452.\n",
            "[I 2024-11-26 00:13:30,671] Trial 106 finished with value: 0.5350027543090061 and parameters: {'eta': 0.05917444380068932, 'learning_rate': 0.010195850240509875, 'max_depth': 3, 'n_estimators': 156, 'subsample': 0.6194416017631098, 'colsample_bytree': 0.549438725418809}. Best is trial 106 with value: 0.5350027543090061.\n",
            "[I 2024-11-26 00:13:31,572] Trial 107 finished with value: 0.6205233792291894 and parameters: {'eta': 0.07766592760248345, 'learning_rate': 0.010758081036540714, 'max_depth': 9, 'n_estimators': 121, 'subsample': 0.640712298707918, 'colsample_bytree': 0.9928999460229517}. Best is trial 106 with value: 0.5350027543090061.\n",
            "[I 2024-11-26 00:13:31,758] Trial 108 finished with value: 0.5287171824111693 and parameters: {'eta': 0.058964189791885495, 'learning_rate': 0.010227254688078754, 'max_depth': 3, 'n_estimators': 151, 'subsample': 0.6226996466237348, 'colsample_bytree': 0.5505979164234674}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:31,968] Trial 109 finished with value: 0.5350027543090061 and parameters: {'eta': 0.06016820442963642, 'learning_rate': 0.010004337536709998, 'max_depth': 3, 'n_estimators': 166, 'subsample': 0.6619230750145477, 'colsample_bytree': 0.5532978238744174}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:32,195] Trial 110 finished with value: 0.5584151859618144 and parameters: {'eta': 0.05987338385002348, 'learning_rate': 0.010282974736416338, 'max_depth': 4, 'n_estimators': 154, 'subsample': 0.663177602772404, 'colsample_bytree': 0.5519099921733337}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:32,451] Trial 111 finished with value: 0.5534032695290295 and parameters: {'eta': 0.060595348481974995, 'learning_rate': 0.010324412295887575, 'max_depth': 3, 'n_estimators': 150, 'subsample': 0.6757872418329723, 'colsample_bytree': 0.5867377177381419}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:32,647] Trial 112 finished with value: 0.5736201874815372 and parameters: {'eta': 0.06009874038701388, 'learning_rate': 0.01405608855086956, 'max_depth': 3, 'n_estimators': 152, 'subsample': 0.6695932506789238, 'colsample_bytree': 0.58908760722431}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:32,881] Trial 113 finished with value: 0.6608169521530964 and parameters: {'eta': 0.05814717751334639, 'learning_rate': 0.09387607336045325, 'max_depth': 4, 'n_estimators': 168, 'subsample': 0.683596663489945, 'colsample_bytree': 0.5555396049427758}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:33,077] Trial 114 finished with value: 0.5554389981940165 and parameters: {'eta': 0.06947110924006022, 'learning_rate': 0.012694199592587784, 'max_depth': 3, 'n_estimators': 129, 'subsample': 0.6623782588526093, 'colsample_bytree': 0.5748831531044871}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:33,240] Trial 115 finished with value: 0.5318697413800747 and parameters: {'eta': 0.06838649049314456, 'learning_rate': 0.013082718478589057, 'max_depth': 3, 'n_estimators': 94, 'subsample': 0.6553152945754334, 'colsample_bytree': 0.5725001087780945}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:33,727] Trial 116 finished with value: 0.5774614470537757 and parameters: {'eta': 0.07005678475778454, 'learning_rate': 0.01324144796305317, 'max_depth': 8, 'n_estimators': 97, 'subsample': 0.6989063073059811, 'colsample_bytree': 0.5767619236129229}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:33,907] Trial 117 finished with value: 0.5584151859618144 and parameters: {'eta': 0.07330038647910302, 'learning_rate': 0.014068376443548847, 'max_depth': 4, 'n_estimators': 82, 'subsample': 0.6697982253683269, 'colsample_bytree': 0.5650055545175057}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:34,110] Trial 118 finished with value: 0.55744008333271 and parameters: {'eta': 0.07426661229744942, 'learning_rate': 0.015330620345424907, 'max_depth': 5, 'n_estimators': 73, 'subsample': 0.6623153602032713, 'colsample_bytree': 0.6008098459256125}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:34,285] Trial 119 finished with value: 0.545217967668675 and parameters: {'eta': 0.07776354363884133, 'learning_rate': 0.015024278228376434, 'max_depth': 5, 'n_estimators': 52, 'subsample': 0.6588873164019029, 'colsample_bytree': 0.6105854415515444}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:34,495] Trial 120 finished with value: 0.5390287044881489 and parameters: {'eta': 0.08727850174751796, 'learning_rate': 0.01514735810457746, 'max_depth': 5, 'n_estimators': 51, 'subsample': 0.6554002172011073, 'colsample_bytree': 0.5860437687705051}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:34,674] Trial 121 finished with value: 0.549433520813732 and parameters: {'eta': 0.08818501816773328, 'learning_rate': 0.015958715409299207, 'max_depth': 5, 'n_estimators': 59, 'subsample': 0.6589218038618897, 'colsample_bytree': 0.6026880139976244}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:34,850] Trial 122 finished with value: 0.5492248578213738 and parameters: {'eta': 0.08750832808606533, 'learning_rate': 0.015730772105979847, 'max_depth': 5, 'n_estimators': 57, 'subsample': 0.6368812669561694, 'colsample_bytree': 0.6041802121167232}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:35,029] Trial 123 finished with value: 0.5473439884121974 and parameters: {'eta': 0.08858156244357322, 'learning_rate': 0.0179561242252973, 'max_depth': 5, 'n_estimators': 51, 'subsample': 0.6352359731025533, 'colsample_bytree': 0.6088899160778335}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:35,211] Trial 124 finished with value: 0.5554389981940165 and parameters: {'eta': 0.08838989077547617, 'learning_rate': 0.01934407906758717, 'max_depth': 5, 'n_estimators': 52, 'subsample': 0.6357635698907735, 'colsample_bytree': 0.587293862801168}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:35,399] Trial 125 finished with value: 0.550382723333152 and parameters: {'eta': 0.08559276694630992, 'learning_rate': 0.01799446430616141, 'max_depth': 5, 'n_estimators': 58, 'subsample': 0.6269630813681355, 'colsample_bytree': 0.6109527308062657}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:35,602] Trial 126 finished with value: 0.55744008333271 and parameters: {'eta': 0.08583875885524773, 'learning_rate': 0.02098183915124343, 'max_depth': 5, 'n_estimators': 56, 'subsample': 0.6320659137787207, 'colsample_bytree': 0.6073962622065331}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:35,791] Trial 127 finished with value: 0.5643154914735511 and parameters: {'eta': 0.09650867100564343, 'learning_rate': 0.017942660645226555, 'max_depth': 5, 'n_estimators': 65, 'subsample': 0.6279689305164727, 'colsample_bytree': 0.6116951052505385}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:36,020] Trial 128 finished with value: 0.5743537010282995 and parameters: {'eta': 0.08324946186209276, 'learning_rate': 0.023105707969605777, 'max_depth': 6, 'n_estimators': 61, 'subsample': 0.6533981309885808, 'colsample_bytree': 0.5932647543195416}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:36,256] Trial 129 finished with value: 0.5651122384283548 and parameters: {'eta': 0.09095111008255044, 'learning_rate': 0.015761415124276104, 'max_depth': 5, 'n_estimators': 90, 'subsample': 0.7001567347220155, 'colsample_bytree': 0.6236282841563735}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:36,478] Trial 130 finished with value: 0.6413627618661621 and parameters: {'eta': 0.09405820695734615, 'learning_rate': 0.05964497791931907, 'max_depth': 5, 'n_estimators': 73, 'subsample': 0.6395107051643963, 'colsample_bytree': 0.5986420367100428}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:36,756] Trial 131 finished with value: 0.5840914478944411 and parameters: {'eta': 0.08261959274344019, 'learning_rate': 0.013574386388647884, 'max_depth': 5, 'n_estimators': 105, 'subsample': 0.6760862905675292, 'colsample_bytree': 0.5718815670555666}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:36,963] Trial 132 finished with value: 0.5574420253698692 and parameters: {'eta': 0.07909094708355617, 'learning_rate': 0.017895757040581387, 'max_depth': 5, 'n_estimators': 69, 'subsample': 0.659311029887523, 'colsample_bytree': 0.5790379000516649}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:37,181] Trial 133 finished with value: 0.5691395929812383 and parameters: {'eta': 0.0859711261398933, 'learning_rate': 0.01567138941602846, 'max_depth': 5, 'n_estimators': 81, 'subsample': 0.6869539151724855, 'colsample_bytree': 0.6138819748539701}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:37,530] Trial 134 finished with value: 0.576086618459869 and parameters: {'eta': 0.09033075216602408, 'learning_rate': 0.012959952184538218, 'max_depth': 6, 'n_estimators': 120, 'subsample': 0.6239340629651055, 'colsample_bytree': 0.5837324353976593}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:37,744] Trial 135 finished with value: 0.5682405771359514 and parameters: {'eta': 0.08071388156413649, 'learning_rate': 0.02004215740771414, 'max_depth': 6, 'n_estimators': 51, 'subsample': 0.7226024041120693, 'colsample_bytree': 0.606298594882009}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:38,088] Trial 136 finished with value: 0.5913044550215667 and parameters: {'eta': 0.0869495417923569, 'learning_rate': 0.013010937815615995, 'max_depth': 5, 'n_estimators': 102, 'subsample': 0.6036938508381817, 'colsample_bytree': 0.9713751519229716}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:38,771] Trial 137 finished with value: 0.6446175464160128 and parameters: {'eta': 0.09445094770153066, 'learning_rate': 0.041351466056293, 'max_depth': 5, 'n_estimators': 135, 'subsample': 0.6439831795718752, 'colsample_bytree': 0.6205151910374994}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:39,768] Trial 138 finished with value: 0.5554389981940165 and parameters: {'eta': 0.08418692146483829, 'learning_rate': 0.01711697769844206, 'max_depth': 5, 'n_estimators': 61, 'subsample': 0.6807155870822768, 'colsample_bytree': 0.5678219680813826}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:40,271] Trial 139 finished with value: 0.5781711566244583 and parameters: {'eta': 0.07461983516470069, 'learning_rate': 0.018910616029761927, 'max_depth': 5, 'n_estimators': 89, 'subsample': 0.6537291789140914, 'colsample_bytree': 0.64020415295982}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:41,368] Trial 140 finished with value: 0.6371008253537216 and parameters: {'eta': 0.06878323540247057, 'learning_rate': 0.04531343866283424, 'max_depth': 5, 'n_estimators': 73, 'subsample': 0.6673057011453442, 'colsample_bytree': 0.5860228850115811}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:41,556] Trial 141 finished with value: 0.5408532206323409 and parameters: {'eta': 0.0883848108922376, 'learning_rate': 0.014963779049175476, 'max_depth': 5, 'n_estimators': 50, 'subsample': 0.6411476851860122, 'colsample_bytree': 0.5916490212178834}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:41,802] Trial 142 finished with value: 0.5482843306559548 and parameters: {'eta': 0.08882514239692192, 'learning_rate': 0.014537180815958424, 'max_depth': 6, 'n_estimators': 59, 'subsample': 0.6353471572528685, 'colsample_bytree': 0.5994794142309204}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:42,012] Trial 143 finished with value: 0.5390287044881489 and parameters: {'eta': 0.08885559087624079, 'learning_rate': 0.01500165523043555, 'max_depth': 6, 'n_estimators': 51, 'subsample': 0.6331881846415522, 'colsample_bytree': 0.5979831049686645}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:42,246] Trial 144 finished with value: 0.5593906515434031 and parameters: {'eta': 0.08925464643147774, 'learning_rate': 0.01526222116719201, 'max_depth': 6, 'n_estimators': 62, 'subsample': 0.6366413889374848, 'colsample_bytree': 0.5997429444737521}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:42,502] Trial 145 finished with value: 0.5613412145736589 and parameters: {'eta': 0.09297585241435126, 'learning_rate': 0.014576038785234117, 'max_depth': 6, 'n_estimators': 52, 'subsample': 0.622692821458484, 'colsample_bytree': 0.8693142417436515}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:42,785] Trial 146 finished with value: 0.6239171116042141 and parameters: {'eta': 0.0877502052763103, 'learning_rate': 0.06711180599262395, 'max_depth': 6, 'n_estimators': 82, 'subsample': 0.6049688181978204, 'colsample_bytree': 0.624822145748116}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:43,041] Trial 147 finished with value: 0.5701477117171709 and parameters: {'eta': 0.08016626946436493, 'learning_rate': 0.022197075716358483, 'max_depth': 7, 'n_estimators': 50, 'subsample': 0.6432252376811288, 'colsample_bytree': 0.6102828501254492}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:43,237] Trial 148 finished with value: 0.5584151859618144 and parameters: {'eta': 0.09140335689679398, 'learning_rate': 0.016536777746448635, 'max_depth': 5, 'n_estimators': 69, 'subsample': 0.63228390972476, 'colsample_bytree': 0.6316023010224259}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:43,440] Trial 149 finished with value: 0.5594072531415242 and parameters: {'eta': 0.08568633418692863, 'learning_rate': 0.020863505821564675, 'max_depth': 5, 'n_estimators': 60, 'subsample': 0.6247664401974987, 'colsample_bytree': 0.5630772719795962}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:43,694] Trial 150 finished with value: 0.5792143481488796 and parameters: {'eta': 0.08438915656270456, 'learning_rate': 0.017545899280381805, 'max_depth': 6, 'n_estimators': 79, 'subsample': 0.651116112761786, 'colsample_bytree': 0.5963588627068941}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:43,963] Trial 151 finished with value: 0.5336551837293745 and parameters: {'eta': 0.06464517730313885, 'learning_rate': 0.01215491185265474, 'max_depth': 6, 'n_estimators': 61, 'subsample': 0.6727728564910128, 'colsample_bytree': 0.5857891435686574}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:44,194] Trial 152 finished with value: 0.5296000114139778 and parameters: {'eta': 0.06422915852761445, 'learning_rate': 0.012485889885054578, 'max_depth': 6, 'n_estimators': 65, 'subsample': 0.5961221194773247, 'colsample_bytree': 0.5782590930691363}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:44,448] Trial 153 finished with value: 0.55148734484463 and parameters: {'eta': 0.06638013821569516, 'learning_rate': 0.013938909335155788, 'max_depth': 6, 'n_estimators': 65, 'subsample': 0.5998636178662529, 'colsample_bytree': 0.5930414183516272}. Best is trial 108 with value: 0.5287171824111693.\n",
            "[I 2024-11-26 00:13:44,650] Trial 154 finished with value: 0.5249387934220251 and parameters: {'eta': 0.08944375591691354, 'learning_rate': 0.01211176297854291, 'max_depth': 6, 'n_estimators': 50, 'subsample': 0.644609456715013, 'colsample_bytree': 0.5762211161604175}. Best is trial 154 with value: 0.5249387934220251.\n",
            "[I 2024-11-26 00:13:44,941] Trial 155 finished with value: 0.5613739492586414 and parameters: {'eta': 0.08925782346314613, 'learning_rate': 0.012744371627171763, 'max_depth': 6, 'n_estimators': 74, 'subsample': 0.645367800152518, 'colsample_bytree': 0.5769704279501835}. Best is trial 154 with value: 0.5249387934220251.\n",
            "[I 2024-11-26 00:13:45,193] Trial 156 finished with value: 0.55744008333271 and parameters: {'eta': 0.09300401348380834, 'learning_rate': 0.015071262015466134, 'max_depth': 6, 'n_estimators': 89, 'subsample': 0.6931124629969172, 'colsample_bytree': 0.5470997966610414}. Best is trial 154 with value: 0.5249387934220251.\n",
            "[I 2024-11-26 00:13:45,445] Trial 157 finished with value: 0.5199918409828244 and parameters: {'eta': 0.09743159388529302, 'learning_rate': 0.012348230228805285, 'max_depth': 7, 'n_estimators': 50, 'subsample': 0.6574591050793096, 'colsample_bytree': 0.5611454838858687}. Best is trial 157 with value: 0.5199918409828244.\n",
            "[I 2024-11-26 00:13:45,691] Trial 158 finished with value: 0.5272900004054097 and parameters: {'eta': 0.09800593730259308, 'learning_rate': 0.011972265043502513, 'max_depth': 7, 'n_estimators': 52, 'subsample': 0.6395382635908008, 'colsample_bytree': 0.5602330374521325}. Best is trial 157 with value: 0.5199918409828244.\n",
            "[I 2024-11-26 00:13:45,971] Trial 159 finished with value: 0.5167480829637842 and parameters: {'eta': 0.0925113178337415, 'learning_rate': 0.012178243316207479, 'max_depth': 7, 'n_estimators': 51, 'subsample': 0.6150038010273241, 'colsample_bytree': 0.558827653069901}. Best is trial 159 with value: 0.5167480829637842.\n",
            "[I 2024-11-26 00:13:46,216] Trial 160 finished with value: 0.5264175548728395 and parameters: {'eta': 0.09540814934667845, 'learning_rate': 0.011842229551068516, 'max_depth': 7, 'n_estimators': 52, 'subsample': 0.6092865736921774, 'colsample_bytree': 0.5607843936151704}. Best is trial 159 with value: 0.5167480829637842.\n",
            "[I 2024-11-26 00:13:46,465] Trial 161 finished with value: 0.517589009436758 and parameters: {'eta': 0.0996581263014792, 'learning_rate': 0.01230501754442746, 'max_depth': 7, 'n_estimators': 50, 'subsample': 0.6082193896202577, 'colsample_bytree': 0.5606295823628209}. Best is trial 159 with value: 0.5167480829637842.\n",
            "[I 2024-11-26 00:13:46,751] Trial 162 finished with value: 0.5390287044881489 and parameters: {'eta': 0.09892474519867273, 'learning_rate': 0.01125858365816736, 'max_depth': 7, 'n_estimators': 71, 'subsample': 0.6085164856192748, 'colsample_bytree': 0.5586207553679794}. Best is trial 159 with value: 0.5167480829637842.\n",
            "[I 2024-11-26 00:13:47,072] Trial 163 finished with value: 0.5309768041298634 and parameters: {'eta': 0.0984036307727264, 'learning_rate': 0.01185793798926668, 'max_depth': 7, 'n_estimators': 69, 'subsample': 0.59489133833782, 'colsample_bytree': 0.5591586318842631}. Best is trial 159 with value: 0.5167480829637842.\n",
            "[I 2024-11-26 00:13:47,389] Trial 164 finished with value: 0.5278341357023167 and parameters: {'eta': 0.09993100324098747, 'learning_rate': 0.01203377935768522, 'max_depth': 7, 'n_estimators': 69, 'subsample': 0.5896706789931686, 'colsample_bytree': 0.5586109556037231}. Best is trial 159 with value: 0.5167480829637842.\n",
            "[I 2024-11-26 00:13:47,678] Trial 165 finished with value: 0.5350027543090061 and parameters: {'eta': 0.09993912837281518, 'learning_rate': 0.012097757281077174, 'max_depth': 7, 'n_estimators': 69, 'subsample': 0.571082712375941, 'colsample_bytree': 0.5589160326974396}. Best is trial 159 with value: 0.5167480829637842.\n",
            "[I 2024-11-26 00:13:48,030] Trial 166 finished with value: 0.5584151859618144 and parameters: {'eta': 0.09958483530631652, 'learning_rate': 0.012188713792274878, 'max_depth': 7, 'n_estimators': 83, 'subsample': 0.5956031138655262, 'colsample_bytree': 0.5635123714605523}. Best is trial 159 with value: 0.5167480829637842.\n",
            "[I 2024-11-26 00:13:48,289] Trial 167 finished with value: 0.5076980109423735 and parameters: {'eta': 0.09691738127355037, 'learning_rate': 0.01234138257880727, 'max_depth': 7, 'n_estimators': 68, 'subsample': 0.5675127636996127, 'colsample_bytree': 0.5459990336173063}. Best is trial 167 with value: 0.5076980109423735.\n",
            "[I 2024-11-26 00:13:48,647] Trial 168 finished with value: 0.5524451796021478 and parameters: {'eta': 0.09727903215460398, 'learning_rate': 0.012662836832873869, 'max_depth': 7, 'n_estimators': 112, 'subsample': 0.5702856997160837, 'colsample_bytree': 0.5511891231914587}. Best is trial 167 with value: 0.5076980109423735.\n",
            "[I 2024-11-26 00:13:48,967] Trial 169 finished with value: 0.5433558297197939 and parameters: {'eta': 0.0965113094316546, 'learning_rate': 0.011942494501906833, 'max_depth': 7, 'n_estimators': 99, 'subsample': 0.5606712911534126, 'colsample_bytree': 0.543785658308097}. Best is trial 167 with value: 0.5076980109423735.\n",
            "[I 2024-11-26 00:13:49,331] Trial 170 finished with value: 0.6384647659919092 and parameters: {'eta': 0.09756712948207108, 'learning_rate': 0.08079769786238171, 'max_depth': 8, 'n_estimators': 66, 'subsample': 0.5800753766217185, 'colsample_bytree': 0.5694517068850491}. Best is trial 167 with value: 0.5076980109423735.\n",
            "[I 2024-11-26 00:13:49,640] Trial 171 finished with value: 0.5473439884121974 and parameters: {'eta': 0.09456873266803423, 'learning_rate': 0.012122268889175803, 'max_depth': 7, 'n_estimators': 75, 'subsample': 0.6128585586773988, 'colsample_bytree': 0.5583877859966675}. Best is trial 167 with value: 0.5076980109423735.\n",
            "[I 2024-11-26 00:13:49,927] Trial 172 finished with value: 0.5255448390985811 and parameters: {'eta': 0.09555989138523081, 'learning_rate': 0.010041100983041347, 'max_depth': 7, 'n_estimators': 66, 'subsample': 0.5937337554863558, 'colsample_bytree': 0.5727516400763929}. Best is trial 167 with value: 0.5076980109423735.\n",
            "[I 2024-11-26 00:13:50,244] Trial 173 finished with value: 0.5167480829637842 and parameters: {'eta': 0.09547979147288321, 'learning_rate': 0.010181655785770566, 'max_depth': 7, 'n_estimators': 90, 'subsample': 0.5883613511656127, 'colsample_bytree': 0.5439022673884601}. Best is trial 167 with value: 0.5076980109423735.\n",
            "[I 2024-11-26 00:13:50,554] Trial 174 finished with value: 0.5208434381929047 and parameters: {'eta': 0.09972571516531505, 'learning_rate': 0.01034318840650843, 'max_depth': 7, 'n_estimators': 91, 'subsample': 0.5895082359996913, 'colsample_bytree': 0.5458759044623099}. Best is trial 167 with value: 0.5076980109423735.\n",
            "[I 2024-11-26 00:13:50,855] Trial 175 finished with value: 0.5327625284848931 and parameters: {'eta': 0.09566562771580105, 'learning_rate': 0.011026964268911943, 'max_depth': 7, 'n_estimators': 93, 'subsample': 0.5875858272233961, 'colsample_bytree': 0.5442784200366743}. Best is trial 167 with value: 0.5076980109423735.\n",
            "[I 2024-11-26 00:13:51,181] Trial 176 finished with value: 0.5167480829637842 and parameters: {'eta': 0.09643636967078974, 'learning_rate': 0.010059166442587447, 'max_depth': 7, 'n_estimators': 89, 'subsample': 0.5891133759751979, 'colsample_bytree': 0.540363190815788}. Best is trial 167 with value: 0.5076980109423735.\n",
            "[I 2024-11-26 00:13:51,908] Trial 177 finished with value: 0.513483383985156 and parameters: {'eta': 0.09577427845302061, 'learning_rate': 0.010015463950308529, 'max_depth': 7, 'n_estimators': 94, 'subsample': 0.589740706211914, 'colsample_bytree': 0.5422394499041315}. Best is trial 167 with value: 0.5076980109423735.\n",
            "[I 2024-11-26 00:13:53,235] Trial 178 finished with value: 0.5402893630569452 and parameters: {'eta': 0.095752202099315, 'learning_rate': 0.013142182206051007, 'max_depth': 7, 'n_estimators': 92, 'subsample': 0.5879734054226385, 'colsample_bytree': 0.5390609798068438}. Best is trial 167 with value: 0.5076980109423735.\n",
            "[I 2024-11-26 00:13:54,468] Trial 179 finished with value: 0.5381164559390216 and parameters: {'eta': 0.09814021153792875, 'learning_rate': 0.01024040936333477, 'max_depth': 7, 'n_estimators': 110, 'subsample': 0.5959144493308933, 'colsample_bytree': 0.5311431341543265}. Best is trial 167 with value: 0.5076980109423735.\n",
            "[I 2024-11-26 00:13:54,763] Trial 180 finished with value: 0.5473439884121974 and parameters: {'eta': 0.09606156071791422, 'learning_rate': 0.01327265822521267, 'max_depth': 7, 'n_estimators': 87, 'subsample': 0.5809972238597971, 'colsample_bytree': 0.5454765790729692}. Best is trial 167 with value: 0.5076980109423735.\n",
            "[I 2024-11-26 00:13:55,127] Trial 181 finished with value: 0.5613739492586414 and parameters: {'eta': 0.09204275336127717, 'learning_rate': 0.011690084113000033, 'max_depth': 7, 'n_estimators': 97, 'subsample': 0.5646413188200247, 'colsample_bytree': 0.5719063968577124}. Best is trial 167 with value: 0.5076980109423735.\n",
            "[I 2024-11-26 00:13:55,470] Trial 182 finished with value: 0.550382723333152 and parameters: {'eta': 0.09505573437366725, 'learning_rate': 0.011898791350850734, 'max_depth': 7, 'n_estimators': 78, 'subsample': 0.5884078517449091, 'colsample_bytree': 0.5640357698436833}. Best is trial 167 with value: 0.5076980109423735.\n",
            "[I 2024-11-26 00:13:55,753] Trial 183 finished with value: 0.5051532772954849 and parameters: {'eta': 0.09818556324141463, 'learning_rate': 0.01011130803151188, 'max_depth': 7, 'n_estimators': 81, 'subsample': 0.6000786798338605, 'colsample_bytree': 0.5419276284122898}. Best is trial 183 with value: 0.5051532772954849.\n",
            "[I 2024-11-26 00:13:56,078] Trial 184 finished with value: 0.55148734484463 and parameters: {'eta': 0.09865918883764219, 'learning_rate': 0.013175479125831838, 'max_depth': 7, 'n_estimators': 96, 'subsample': 0.6033721217195135, 'colsample_bytree': 0.53250641458375}. Best is trial 183 with value: 0.5051532772954849.\n",
            "[I 2024-11-26 00:13:56,404] Trial 185 finished with value: 0.5085051852542475 and parameters: {'eta': 0.09805582464952715, 'learning_rate': 0.010466544444324426, 'max_depth': 7, 'n_estimators': 85, 'subsample': 0.595652356011674, 'colsample_bytree': 0.5483766006401232}. Best is trial 183 with value: 0.5051532772954849.\n",
            "[I 2024-11-26 00:13:56,690] Trial 186 finished with value: 0.5043575496867727 and parameters: {'eta': 0.0977120107822745, 'learning_rate': 0.010506369555695786, 'max_depth': 7, 'n_estimators': 82, 'subsample': 0.5980261218621442, 'colsample_bytree': 0.5547725681585638}. Best is trial 186 with value: 0.5043575496867727.\n",
            "[I 2024-11-26 00:13:57,048] Trial 187 finished with value: 0.5603904058111507 and parameters: {'eta': 0.09770978266746015, 'learning_rate': 0.0102370671500883, 'max_depth': 7, 'n_estimators': 81, 'subsample': 0.5986042436335357, 'colsample_bytree': 0.7560733344691916}. Best is trial 186 with value: 0.5043575496867727.\n",
            "[I 2024-11-26 00:13:57,365] Trial 188 finished with value: 0.5051532772954849 and parameters: {'eta': 0.09978600647844717, 'learning_rate': 0.010363594296065206, 'max_depth': 8, 'n_estimators': 66, 'subsample': 0.5732396408206881, 'colsample_bytree': 0.5396759442740056}. Best is trial 186 with value: 0.5043575496867727.\n",
            "[I 2024-11-26 00:13:57,692] Trial 189 finished with value: 0.5110165610272256 and parameters: {'eta': 0.09346822589135151, 'learning_rate': 0.01040816597501417, 'max_depth': 8, 'n_estimators': 80, 'subsample': 0.5557775154119214, 'colsample_bytree': 0.5413070204169351}. Best is trial 186 with value: 0.5043575496867727.\n",
            "[I 2024-11-26 00:13:58,099] Trial 190 finished with value: 0.550382723333152 and parameters: {'eta': 0.09372976824712272, 'learning_rate': 0.010736002698640048, 'max_depth': 8, 'n_estimators': 105, 'subsample': 0.5450061856438488, 'colsample_bytree': 0.5293484749908822}. Best is trial 186 with value: 0.5043575496867727.\n",
            "[I 2024-11-26 00:13:58,455] Trial 191 finished with value: 0.5051532772954849 and parameters: {'eta': 0.09934098441445544, 'learning_rate': 0.010037354142603892, 'max_depth': 8, 'n_estimators': 77, 'subsample': 0.573356208035719, 'colsample_bytree': 0.5420167288666156}. Best is trial 186 with value: 0.5043575496867727.\n",
            "[I 2024-11-26 00:13:58,798] Trial 192 finished with value: 0.5068901185042486 and parameters: {'eta': 0.09990422642376952, 'learning_rate': 0.01002585784264645, 'max_depth': 8, 'n_estimators': 85, 'subsample': 0.5741301333098074, 'colsample_bytree': 0.5434774854730625}. Best is trial 186 with value: 0.5043575496867727.\n",
            "[I 2024-11-26 00:13:59,138] Trial 193 finished with value: 0.5043575496867727 and parameters: {'eta': 0.09992155914300789, 'learning_rate': 0.010074766684370535, 'max_depth': 8, 'n_estimators': 84, 'subsample': 0.5568142886891428, 'colsample_bytree': 0.532247769715027}. Best is trial 186 with value: 0.5043575496867727.\n",
            "[I 2024-11-26 00:13:59,502] Trial 194 finished with value: 0.5076980109423735 and parameters: {'eta': 0.0973685834488294, 'learning_rate': 0.010025651234032918, 'max_depth': 8, 'n_estimators': 86, 'subsample': 0.5566456323742637, 'colsample_bytree': 0.5390738110247543}. Best is trial 186 with value: 0.5043575496867727.\n",
            "[I 2024-11-26 00:13:59,834] Trial 195 finished with value: 0.5110165610272256 and parameters: {'eta': 0.09672328491029436, 'learning_rate': 0.010182888960811265, 'max_depth': 8, 'n_estimators': 84, 'subsample': 0.5538119397989679, 'colsample_bytree': 0.5395902905529989}. Best is trial 186 with value: 0.5043575496867727.\n",
            "[I 2024-11-26 00:14:00,178] Trial 196 finished with value: 0.5009949014744384 and parameters: {'eta': 0.09678735718072894, 'learning_rate': 0.01013753637473824, 'max_depth': 8, 'n_estimators': 82, 'subsample': 0.5545842610999997, 'colsample_bytree': 0.5404714373883382}. Best is trial 196 with value: 0.5009949014744384.\n",
            "[I 2024-11-26 00:14:00,546] Trial 197 finished with value: 0.5068901185042486 and parameters: {'eta': 0.0969386746460654, 'learning_rate': 0.010230548721713062, 'max_depth': 8, 'n_estimators': 85, 'subsample': 0.5543661179075876, 'colsample_bytree': 0.5372242467591302}. Best is trial 196 with value: 0.5009949014744384.\n",
            "[I 2024-11-26 00:14:00,954] Trial 198 finished with value: 0.5612465694366069 and parameters: {'eta': 0.09745451290983315, 'learning_rate': 0.013587020484420172, 'max_depth': 8, 'n_estimators': 117, 'subsample': 0.5536898600403839, 'colsample_bytree': 0.5281777164573781}. Best is trial 196 with value: 0.5009949014744384.\n",
            "[I 2024-11-26 00:14:01,299] Trial 199 finished with value: 0.517589009436758 and parameters: {'eta': 0.09972260024271164, 'learning_rate': 0.010125283784386839, 'max_depth': 8, 'n_estimators': 87, 'subsample': 0.553383525688246, 'colsample_bytree': 0.5417045912693756}. Best is trial 196 with value: 0.5009949014744384.\n",
            "[I 2024-11-26 00:14:01,652] Trial 200 finished with value: 0.5350027543090061 and parameters: {'eta': 0.09636718403184721, 'learning_rate': 0.013859626780560881, 'max_depth': 8, 'n_estimators': 82, 'subsample': 0.5417290402715246, 'colsample_bytree': 0.5378099112165479}. Best is trial 196 with value: 0.5009949014744384.\n",
            "[I 2024-11-26 00:14:02,011] Trial 201 finished with value: 0.5101974839018145 and parameters: {'eta': 0.09897337616176324, 'learning_rate': 0.01021888841046429, 'max_depth': 8, 'n_estimators': 86, 'subsample': 0.5546249869176358, 'colsample_bytree': 0.520753226081459}. Best is trial 196 with value: 0.5009949014744384.\n",
            "[I 2024-11-26 00:14:02,353] Trial 202 finished with value: 0.5350027543090061 and parameters: {'eta': 0.09295046668785627, 'learning_rate': 0.01361705766326686, 'max_depth': 8, 'n_estimators': 86, 'subsample': 0.5579647567466062, 'colsample_bytree': 0.5226978269892365}. Best is trial 196 with value: 0.5009949014744384.\n",
            "[I 2024-11-26 00:14:02,769] Trial 203 finished with value: 0.5278341357023167 and parameters: {'eta': 0.0999409311203543, 'learning_rate': 0.010075130789198973, 'max_depth': 8, 'n_estimators': 107, 'subsample': 0.5343845858412952, 'colsample_bytree': 0.5386493998329616}. Best is trial 196 with value: 0.5009949014744384.\n",
            "[I 2024-11-26 00:14:03,185] Trial 204 finished with value: 0.5350027543090061 and parameters: {'eta': 0.09727602056062011, 'learning_rate': 0.010610976932290406, 'max_depth': 8, 'n_estimators': 102, 'subsample': 0.5697728525710942, 'colsample_bytree': 0.5146528179766743}. Best is trial 196 with value: 0.5009949014744384.\n",
            "[I 2024-11-26 00:14:03,523] Trial 205 finished with value: 0.5043575496867727 and parameters: {'eta': 0.09406963913758323, 'learning_rate': 0.010034338173778998, 'max_depth': 8, 'n_estimators': 78, 'subsample': 0.5535488654987512, 'colsample_bytree': 0.5285506484071021}. Best is trial 196 with value: 0.5009949014744384.\n",
            "[I 2024-11-26 00:14:03,860] Trial 206 finished with value: 0.5110165610272256 and parameters: {'eta': 0.09414157254412543, 'learning_rate': 0.010088166125452986, 'max_depth': 8, 'n_estimators': 79, 'subsample': 0.5505334377976209, 'colsample_bytree': 0.5280503090929207}. Best is trial 196 with value: 0.5009949014744384.\n",
            "[I 2024-11-26 00:14:04,193] Trial 207 finished with value: 0.5110165610272256 and parameters: {'eta': 0.0938676544989202, 'learning_rate': 0.010003322391441135, 'max_depth': 8, 'n_estimators': 78, 'subsample': 0.5470705194508547, 'colsample_bytree': 0.5197660849028062}. Best is trial 196 with value: 0.5009949014744384.\n",
            "[I 2024-11-26 00:14:04,695] Trial 208 finished with value: 0.5318697413800747 and parameters: {'eta': 0.09392678419020814, 'learning_rate': 0.013818885753173684, 'max_depth': 8, 'n_estimators': 79, 'subsample': 0.5436698232070967, 'colsample_bytree': 0.524296653887348}. Best is trial 196 with value: 0.5009949014744384.\n",
            "[I 2024-11-26 00:14:06,027] Trial 209 finished with value: 0.4976097861376442 and parameters: {'eta': 0.091266076744031, 'learning_rate': 0.010133837434724464, 'max_depth': 8, 'n_estimators': 78, 'subsample': 0.5304167055564171, 'colsample_bytree': 0.5170668447940803}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:06,817] Trial 210 finished with value: 0.5076980109423735 and parameters: {'eta': 0.09252171529873689, 'learning_rate': 0.010190696346056209, 'max_depth': 8, 'n_estimators': 78, 'subsample': 0.5669060307922156, 'colsample_bytree': 0.5170643033040268}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:07,597] Trial 211 finished with value: 0.5043575496867727 and parameters: {'eta': 0.09129848720947449, 'learning_rate': 0.010287448057844885, 'max_depth': 8, 'n_estimators': 78, 'subsample': 0.5278342879551835, 'colsample_bytree': 0.5198436234853853}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:07,941] Trial 212 finished with value: 0.5051532772954849 and parameters: {'eta': 0.0915289543795256, 'learning_rate': 0.010089374916189848, 'max_depth': 8, 'n_estimators': 78, 'subsample': 0.5331266712738109, 'colsample_bytree': 0.5167558979058797}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:08,323] Trial 213 finished with value: 0.5043575496867727 and parameters: {'eta': 0.0918042173021785, 'learning_rate': 0.010379133417369757, 'max_depth': 8, 'n_estimators': 80, 'subsample': 0.5342827641749368, 'colsample_bytree': 0.5170213711750036}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:08,639] Trial 214 finished with value: 0.5009949014744384 and parameters: {'eta': 0.09180691663037818, 'learning_rate': 0.010147858553483918, 'max_depth': 8, 'n_estimators': 77, 'subsample': 0.5298862003632772, 'colsample_bytree': 0.5124935935447318}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:08,971] Trial 215 finished with value: 0.5246718363374454 and parameters: {'eta': 0.09100404608700419, 'learning_rate': 0.01397107570090268, 'max_depth': 8, 'n_estimators': 76, 'subsample': 0.5276590621656936, 'colsample_bytree': 0.510384645605231}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:09,340] Trial 216 finished with value: 0.517589009436758 and parameters: {'eta': 0.0929436412144379, 'learning_rate': 0.011821670423095095, 'max_depth': 9, 'n_estimators': 77, 'subsample': 0.5250694574810335, 'colsample_bytree': 0.5173951826115046}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:09,719] Trial 217 finished with value: 0.5372041873632771 and parameters: {'eta': 0.09187495180577392, 'learning_rate': 0.011793418047844508, 'max_depth': 8, 'n_estimators': 100, 'subsample': 0.5323893112152832, 'colsample_bytree': 0.5289831559949392}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:10,076] Trial 218 finished with value: 0.5390287044881489 and parameters: {'eta': 0.09101627104667215, 'learning_rate': 0.013886942589340222, 'max_depth': 8, 'n_estimators': 84, 'subsample': 0.5623099435715105, 'colsample_bytree': 0.5145462024078286}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:10,402] Trial 219 finished with value: 0.5043575496867727 and parameters: {'eta': 0.094176348656556, 'learning_rate': 0.010004619082407604, 'max_depth': 8, 'n_estimators': 77, 'subsample': 0.5404811865141977, 'colsample_bytree': 0.5268859901050212}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:10,705] Trial 220 finished with value: 0.5017789995306928 and parameters: {'eta': 0.0976197334475623, 'learning_rate': 0.010046006460285946, 'max_depth': 8, 'n_estimators': 72, 'subsample': 0.5345574523353478, 'colsample_bytree': 0.5100704231983788}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:11,043] Trial 221 finished with value: 0.5076980109423735 and parameters: {'eta': 0.09782522183691174, 'learning_rate': 0.011711699332517585, 'max_depth': 8, 'n_estimators': 73, 'subsample': 0.5379934804322348, 'colsample_bytree': 0.511435865936015}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:11,355] Trial 222 finished with value: 0.5118350024470595 and parameters: {'eta': 0.09812015338336803, 'learning_rate': 0.011537213112531884, 'max_depth': 8, 'n_estimators': 73, 'subsample': 0.5372841210373506, 'colsample_bytree': 0.5113351418236101}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:11,655] Trial 223 finished with value: 0.5126527277346637 and parameters: {'eta': 0.09464058327737108, 'learning_rate': 0.013585043061078791, 'max_depth': 8, 'n_estimators': 70, 'subsample': 0.5192661063230998, 'colsample_bytree': 0.5204157301351272}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:11,994] Trial 224 finished with value: 0.5208434381929047 and parameters: {'eta': 0.09802801151075959, 'learning_rate': 0.012065827413559178, 'max_depth': 8, 'n_estimators': 76, 'subsample': 0.539340066997774, 'colsample_bytree': 0.5079096314701405}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:12,375] Trial 225 finished with value: 0.5433558297197939 and parameters: {'eta': 0.09158305199486066, 'learning_rate': 0.011951232906906365, 'max_depth': 8, 'n_estimators': 98, 'subsample': 0.5638275801891193, 'colsample_bytree': 0.5276644169169464}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:12,712] Trial 226 finished with value: 0.5076980109423735 and parameters: {'eta': 0.09778908308532075, 'learning_rate': 0.010013347201557646, 'max_depth': 8, 'n_estimators': 86, 'subsample': 0.526760953549697, 'colsample_bytree': 0.5007276047502356}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:13,018] Trial 227 finished with value: 0.5035610194376876 and parameters: {'eta': 0.09811244384329601, 'learning_rate': 0.012848281207726287, 'max_depth': 8, 'n_estimators': 68, 'subsample': 0.5252835479853831, 'colsample_bytree': 0.5078071605952192}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:14,457] Trial 228 finished with value: 0.6438601894518217 and parameters: {'eta': 0.09685544624459515, 'learning_rate': 0.01410911831308068, 'max_depth': 9, 'n_estimators': 407, 'subsample': 0.5085099797440643, 'colsample_bytree': 0.5023495707797534}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:14,749] Trial 229 finished with value: 0.5076980109423735 and parameters: {'eta': 0.09482863625478989, 'learning_rate': 0.013222996741772543, 'max_depth': 8, 'n_estimators': 66, 'subsample': 0.5242477633559394, 'colsample_bytree': 0.5090125487429592}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:15,059] Trial 230 finished with value: 0.5101974839018145 and parameters: {'eta': 0.09502904455293522, 'learning_rate': 0.013586808736022481, 'max_depth': 8, 'n_estimators': 65, 'subsample': 0.5295254450378774, 'colsample_bytree': 0.5113620684019954}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:15,362] Trial 231 finished with value: 0.5076980109423735 and parameters: {'eta': 0.09783323648106747, 'learning_rate': 0.01210021549512672, 'max_depth': 8, 'n_estimators': 72, 'subsample': 0.5237100485450228, 'colsample_bytree': 0.5000350914883396}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:15,656] Trial 232 finished with value: 0.5101974839018145 and parameters: {'eta': 0.09626274227261024, 'learning_rate': 0.012365656591105603, 'max_depth': 8, 'n_estimators': 69, 'subsample': 0.5223315437009645, 'colsample_bytree': 0.5015891387594907}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:15,953] Trial 233 finished with value: 0.5372041873632771 and parameters: {'eta': 0.0999559836299548, 'learning_rate': 0.015427187213403065, 'max_depth': 8, 'n_estimators': 72, 'subsample': 0.5386566582884179, 'colsample_bytree': 0.51022639052005}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:16,264] Trial 234 finished with value: 0.5043575496867727 and parameters: {'eta': 0.09767684479135079, 'learning_rate': 0.011725226131023576, 'max_depth': 8, 'n_estimators': 67, 'subsample': 0.5141832131721039, 'colsample_bytree': 0.5171811481628256}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:16,563] Trial 235 finished with value: 0.5076980109423735 and parameters: {'eta': 0.09476588493322897, 'learning_rate': 0.013290157698802187, 'max_depth': 8, 'n_estimators': 65, 'subsample': 0.5001415993105479, 'colsample_bytree': 0.5182279126973276}. Best is trial 209 with value: 0.4976097861376442.\n",
            "[I 2024-11-26 00:14:16,846] Trial 236 finished with value: 0.4915190896749492 and parameters: {'eta': 0.09258443736076304, 'learning_rate': 0.010060257942545678, 'max_depth': 8, 'n_estimators': 62, 'subsample': 0.5192758205775629, 'colsample_bytree': 0.5287401972180237}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:17,205] Trial 237 finished with value: 0.5043575496867727 and parameters: {'eta': 0.0908117646047337, 'learning_rate': 0.010068579248673097, 'max_depth': 8, 'n_estimators': 77, 'subsample': 0.511812535736952, 'colsample_bytree': 0.5296981608392997}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:17,719] Trial 238 finished with value: 0.5110165610272256 and parameters: {'eta': 0.09079197063490865, 'learning_rate': 0.011559441181409095, 'max_depth': 8, 'n_estimators': 77, 'subsample': 0.5117127068875496, 'colsample_bytree': 0.5307499578133894}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:19,512] Trial 239 finished with value: 0.5143134714320514 and parameters: {'eta': 0.09241571128156993, 'learning_rate': 0.010067721503887402, 'max_depth': 8, 'n_estimators': 91, 'subsample': 0.5133570504134729, 'colsample_bytree': 0.5283108417788865}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:20,380] Trial 240 finished with value: 0.517589009436758 and parameters: {'eta': 0.09043802538022211, 'learning_rate': 0.01179153355757662, 'max_depth': 8, 'n_estimators': 77, 'subsample': 0.5380843224943591, 'colsample_bytree': 0.5228947559017609}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:20,652] Trial 241 finished with value: 0.5017789995306928 and parameters: {'eta': 0.09727255908315421, 'learning_rate': 0.011705450771954394, 'max_depth': 8, 'n_estimators': 62, 'subsample': 0.5295015313660243, 'colsample_bytree': 0.5166631342199758}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:20,921] Trial 242 finished with value: 0.6136944931540819 and parameters: {'eta': 0.09640373528644415, 'learning_rate': 0.050304062790925405, 'max_depth': 8, 'n_estimators': 63, 'subsample': 0.5456212340554757, 'colsample_bytree': 0.5176210498520426}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:21,216] Trial 243 finished with value: 0.5051532772954849 and parameters: {'eta': 0.09279167484159895, 'learning_rate': 0.01186123357459519, 'max_depth': 8, 'n_estimators': 64, 'subsample': 0.5718946049900085, 'colsample_bytree': 0.5321182343428967}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:21,507] Trial 244 finished with value: 0.5009949014744384 and parameters: {'eta': 0.09192540718941887, 'learning_rate': 0.011810348197876746, 'max_depth': 8, 'n_estimators': 62, 'subsample': 0.5666184270412031, 'colsample_bytree': 0.5328578224203951}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:21,797] Trial 245 finished with value: 0.5167480829637842 and parameters: {'eta': 0.09347621037101633, 'learning_rate': 0.014476736391006377, 'max_depth': 8, 'n_estimators': 62, 'subsample': 0.5724551537661426, 'colsample_bytree': 0.5324331904515842}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:22,101] Trial 246 finished with value: 0.5043575496867727 and parameters: {'eta': 0.09037326420169094, 'learning_rate': 0.012015698861940507, 'max_depth': 8, 'n_estimators': 69, 'subsample': 0.5143773724051227, 'colsample_bytree': 0.5331897035877947}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:22,420] Trial 247 finished with value: 0.6006740886750297 and parameters: {'eta': 0.09014531360317686, 'learning_rate': 0.03863311799413924, 'max_depth': 8, 'n_estimators': 62, 'subsample': 0.5140500895605308, 'colsample_bytree': 0.5333096769302149}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:22,698] Trial 248 finished with value: 0.5118350024470595 and parameters: {'eta': 0.09184343657559435, 'learning_rate': 0.013024510396071014, 'max_depth': 8, 'n_estimators': 62, 'subsample': 0.5169343703956019, 'colsample_bytree': 0.5301911201388624}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:22,992] Trial 249 finished with value: 0.5159066651614015 and parameters: {'eta': 0.09448906231203236, 'learning_rate': 0.014716779280420048, 'max_depth': 8, 'n_estimators': 69, 'subsample': 0.5031564684237336, 'colsample_bytree': 0.527217737949894}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:23,271] Trial 250 finished with value: 0.49838206846778627 and parameters: {'eta': 0.09295814511548123, 'learning_rate': 0.011883405473065501, 'max_depth': 8, 'n_estimators': 59, 'subsample': 0.5297077773681192, 'colsample_bytree': 0.5196086511887278}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:23,564] Trial 251 finished with value: 0.49838206846778627 and parameters: {'eta': 0.09076947895918412, 'learning_rate': 0.011823180861701341, 'max_depth': 8, 'n_estimators': 60, 'subsample': 0.5324356395828516, 'colsample_bytree': 0.5197610823668912}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:23,833] Trial 252 finished with value: 0.5287171824111693 and parameters: {'eta': 0.09030309598885035, 'learning_rate': 0.015905783431571115, 'max_depth': 8, 'n_estimators': 61, 'subsample': 0.5278873365565082, 'colsample_bytree': 0.5213434220706741}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:24,111] Trial 253 finished with value: 0.5051532772954849 and parameters: {'eta': 0.09242597499604666, 'learning_rate': 0.012355070159422901, 'max_depth': 8, 'n_estimators': 59, 'subsample': 0.5317632528382928, 'colsample_bytree': 0.5181316836755119}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:24,433] Trial 254 finished with value: 0.5216946348883602 and parameters: {'eta': 0.09219074341120462, 'learning_rate': 0.013347557974836848, 'max_depth': 8, 'n_estimators': 61, 'subsample': 0.531296037493318, 'colsample_bytree': 0.5158927653551916}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:24,698] Trial 255 finished with value: 0.5143134714320514 and parameters: {'eta': 0.08986811192879696, 'learning_rate': 0.016041808052312742, 'max_depth': 8, 'n_estimators': 58, 'subsample': 0.5114259090125087, 'colsample_bytree': 0.522306497106253}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:25,003] Trial 256 finished with value: 0.513483383985156 and parameters: {'eta': 0.09271392677065313, 'learning_rate': 0.012178513836883537, 'max_depth': 8, 'n_estimators': 71, 'subsample': 0.5222526616451191, 'colsample_bytree': 0.5110894317353795}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:25,323] Trial 257 finished with value: 0.5126527277346637 and parameters: {'eta': 0.09066133034073344, 'learning_rate': 0.014590262054318622, 'max_depth': 9, 'n_estimators': 62, 'subsample': 0.5333832034263746, 'colsample_bytree': 0.5280342960744213}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:25,610] Trial 258 finished with value: 0.5017789995306928 and parameters: {'eta': 0.09363300538090542, 'learning_rate': 0.011973379413450298, 'max_depth': 8, 'n_estimators': 58, 'subsample': 0.5455050627188986, 'colsample_bytree': 0.5174017416189884}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:25,908] Trial 259 finished with value: 0.5076980109423735 and parameters: {'eta': 0.09492131038632101, 'learning_rate': 0.011770566079944717, 'max_depth': 8, 'n_estimators': 72, 'subsample': 0.5455971386252328, 'colsample_bytree': 0.5265017117403527}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:26,985] Trial 260 finished with value: 0.6385091459708855 and parameters: {'eta': 0.09317991025794228, 'learning_rate': 0.014185470307938262, 'max_depth': 8, 'n_estimators': 368, 'subsample': 0.5185284007052818, 'colsample_bytree': 0.5327299764768436}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:27,338] Trial 261 finished with value: 0.55148734484463 and parameters: {'eta': 0.08934515201094252, 'learning_rate': 0.011909797589094134, 'max_depth': 8, 'n_estimators': 59, 'subsample': 0.5084196874457345, 'colsample_bytree': 0.7932766504101786}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:27,663] Trial 262 finished with value: 0.5167480829637842 and parameters: {'eta': 0.09431937483017841, 'learning_rate': 0.013385479833439101, 'max_depth': 8, 'n_estimators': 73, 'subsample': 0.5410616784701345, 'colsample_bytree': 0.5097971154795804}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:27,979] Trial 263 finished with value: 0.5199918409828244 and parameters: {'eta': 0.08701289402988809, 'learning_rate': 0.011703811948621658, 'max_depth': 8, 'n_estimators': 77, 'subsample': 0.5446289054574384, 'colsample_bytree': 0.5183095625377411}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:28,272] Trial 264 finished with value: 0.5237985300245587 and parameters: {'eta': 0.09136977281385113, 'learning_rate': 0.016278927787514823, 'max_depth': 8, 'n_estimators': 68, 'subsample': 0.5198328114609622, 'colsample_bytree': 0.5336011628420302}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:28,569] Trial 265 finished with value: 0.5151430035502025 and parameters: {'eta': 0.09502998676280451, 'learning_rate': 0.013654032512005235, 'max_depth': 8, 'n_estimators': 60, 'subsample': 0.5318453718249797, 'colsample_bytree': 0.5076568365042345}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:28,940] Trial 266 finished with value: 0.5043575496867727 and parameters: {'eta': 0.09346388489912133, 'learning_rate': 0.010054291363311811, 'max_depth': 9, 'n_estimators': 79, 'subsample': 0.5009011085223753, 'colsample_bytree': 0.5223279468505235}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:29,807] Trial 267 finished with value: 0.5167480829637842 and parameters: {'eta': 0.09581402648828619, 'learning_rate': 0.010070806163175508, 'max_depth': 9, 'n_estimators': 94, 'subsample': 0.5080798223298408, 'colsample_bytree': 0.5184983931797974}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:30,169] Trial 268 finished with value: 0.6256598827584757 and parameters: {'eta': 0.08917494619974317, 'learning_rate': 0.07325506853769576, 'max_depth': 9, 'n_estimators': 79, 'subsample': 0.5173923975908572, 'colsample_bytree': 0.5091806712407801}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:30,765] Trial 269 finished with value: 0.5110165610272256 and parameters: {'eta': 0.0939758485752776, 'learning_rate': 0.010039213311623564, 'max_depth': 9, 'n_estimators': 79, 'subsample': 0.5031168368268601, 'colsample_bytree': 0.5240669647903377}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:34,170] Trial 270 finished with value: 0.6239156559159746 and parameters: {'eta': 0.09146564909810959, 'learning_rate': 0.011861864030046243, 'max_depth': 8, 'n_estimators': 440, 'subsample': 0.5243143103250513, 'colsample_bytree': 0.5160577663790326}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:34,552] Trial 271 finished with value: 0.5384459814747401 and parameters: {'eta': 0.09563957289355358, 'learning_rate': 0.014894869784495274, 'max_depth': 8, 'n_estimators': 95, 'subsample': 0.5001594976023693, 'colsample_bytree': 0.5353717261686292}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:34,893] Trial 272 finished with value: 0.5017789995306928 and parameters: {'eta': 0.09859639737260212, 'learning_rate': 0.010005201281473416, 'max_depth': 8, 'n_estimators': 71, 'subsample': 0.5461603132093032, 'colsample_bytree': 0.5069317210830725}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:35,277] Trial 273 finished with value: 0.6282649996256745 and parameters: {'eta': 0.09873137167954397, 'learning_rate': 0.09995252230809885, 'max_depth': 10, 'n_estimators': 71, 'subsample': 0.5523314736717702, 'colsample_bytree': 0.5006401212615543}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:35,565] Trial 274 finished with value: 0.5009949014744384 and parameters: {'eta': 0.09873090678427311, 'learning_rate': 0.011702335295168377, 'max_depth': 8, 'n_estimators': 59, 'subsample': 0.5445820435964764, 'colsample_bytree': 0.5251008966180474}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:35,853] Trial 275 finished with value: 0.6405146076456543 and parameters: {'eta': 0.0964033326854784, 'learning_rate': 0.09051107024338599, 'max_depth': 8, 'n_estimators': 56, 'subsample': 0.543694985389046, 'colsample_bytree': 0.5239216494682972}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:36,138] Trial 276 finished with value: 0.49496219607232284 and parameters: {'eta': 0.09801392123768639, 'learning_rate': 0.013226088150803098, 'max_depth': 8, 'n_estimators': 57, 'subsample': 0.5365299818979198, 'colsample_bytree': 0.5127033913472552}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:36,424] Trial 277 finished with value: 0.5017789995306928 and parameters: {'eta': 0.0938575480168724, 'learning_rate': 0.013618627989895242, 'max_depth': 8, 'n_estimators': 57, 'subsample': 0.5362951825516739, 'colsample_bytree': 0.500073401657734}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:36,826] Trial 278 finished with value: 0.5707999430796316 and parameters: {'eta': 0.09419189909313129, 'learning_rate': 0.015304344358381187, 'max_depth': 8, 'n_estimators': 57, 'subsample': 0.5365950794590695, 'colsample_bytree': 0.8257605308405063}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:37,127] Trial 279 finished with value: 0.522352469506941 and parameters: {'eta': 0.09334380593979832, 'learning_rate': 0.016809122801459294, 'max_depth': 8, 'n_estimators': 61, 'subsample': 0.5240391355244645, 'colsample_bytree': 0.5092253460629393}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:37,466] Trial 280 finished with value: 0.554472464407902 and parameters: {'eta': 0.09672703139156769, 'learning_rate': 0.013036425852870077, 'max_depth': 8, 'n_estimators': 56, 'subsample': 0.5423083831104382, 'colsample_bytree': 0.7220731444905811}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:37,771] Trial 281 finished with value: 0.5126527277346637 and parameters: {'eta': 0.09519556042137374, 'learning_rate': 0.01390305494118517, 'max_depth': 8, 'n_estimators': 69, 'subsample': 0.5167150238001379, 'colsample_bytree': 0.5125486071513956}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:38,097] Trial 282 finished with value: 0.6218940995030559 and parameters: {'eta': 0.08993819949536894, 'learning_rate': 0.055718234186674834, 'max_depth': 10, 'n_estimators': 51, 'subsample': 0.5316174363795249, 'colsample_bytree': 0.5051874184529321}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:38,456] Trial 283 finished with value: 0.5110165610272256 and parameters: {'eta': 0.09335805434526032, 'learning_rate': 0.013119846036257491, 'max_depth': 8, 'n_estimators': 68, 'subsample': 0.5490049198996989, 'colsample_bytree': 0.5017123695188004}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:38,718] Trial 284 finished with value: 0.5085051852542475 and parameters: {'eta': 0.08761738608018374, 'learning_rate': 0.014986099281851682, 'max_depth': 8, 'n_estimators': 56, 'subsample': 0.5271324182152028, 'colsample_bytree': 0.5209832691851981}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:39,042] Trial 285 finished with value: 0.5085051852542475 and parameters: {'eta': 0.09595708671015409, 'learning_rate': 0.011997396532522622, 'max_depth': 8, 'n_estimators': 68, 'subsample': 0.5377114276712501, 'colsample_bytree': 0.5102506031098917}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:39,355] Trial 286 finished with value: 0.5350027543090061 and parameters: {'eta': 0.09151412633092156, 'learning_rate': 0.016483132959272853, 'max_depth': 8, 'n_estimators': 71, 'subsample': 0.5084414884974245, 'colsample_bytree': 0.5231525346128343}. Best is trial 236 with value: 0.4915190896749492.\n",
            "[I 2024-11-26 00:14:39,609] Trial 287 finished with value: 0.4880524518765835 and parameters: {'eta': 0.09382206274702579, 'learning_rate': 0.012345874975257468, 'max_depth': 8, 'n_estimators': 50, 'subsample': 0.5235910464504485, 'colsample_bytree': 0.5090806736295134}. Best is trial 287 with value: 0.4880524518765835.\n",
            "[I 2024-11-26 00:14:39,876] Trial 288 finished with value: 0.4915190896749492 and parameters: {'eta': 0.09768045158902468, 'learning_rate': 0.013779924765633597, 'max_depth': 8, 'n_estimators': 51, 'subsample': 0.5478339517494781, 'colsample_bytree': 0.5000387942949949}. Best is trial 287 with value: 0.4880524518765835.\n",
            "[I 2024-11-26 00:14:40,140] Trial 289 finished with value: 0.4976097861376442 and parameters: {'eta': 0.09817165000110804, 'learning_rate': 0.014485741456123618, 'max_depth': 8, 'n_estimators': 50, 'subsample': 0.5493002394103487, 'colsample_bytree': 0.5021817517340434}. Best is trial 287 with value: 0.4880524518765835.\n",
            "[I 2024-11-26 00:14:40,401] Trial 290 finished with value: 0.5159066651614015 and parameters: {'eta': 0.09814505604611941, 'learning_rate': 0.01748946959574809, 'max_depth': 8, 'n_estimators': 52, 'subsample': 0.5446576525067903, 'colsample_bytree': 0.5010113461264042}. Best is trial 287 with value: 0.4880524518765835.\n",
            "[I 2024-11-26 00:14:40,649] Trial 291 finished with value: 0.5068901185042486 and parameters: {'eta': 0.09799741152924397, 'learning_rate': 0.014998546944247458, 'max_depth': 8, 'n_estimators': 52, 'subsample': 0.5547866020124645, 'colsample_bytree': 0.5086662357870358}. Best is trial 287 with value: 0.4880524518765835.\n",
            "[I 2024-11-26 00:14:40,945] Trial 292 finished with value: 0.5076980109423735 and parameters: {'eta': 0.09660500985512177, 'learning_rate': 0.01382987415995293, 'max_depth': 8, 'n_estimators': 59, 'subsample': 0.548720875284439, 'colsample_bytree': 0.5007046899578621}. Best is trial 287 with value: 0.4880524518765835.\n",
            "[I 2024-11-26 00:14:41,195] Trial 293 finished with value: 0.5068901185042486 and parameters: {'eta': 0.09851438697795581, 'learning_rate': 0.016602099262472664, 'max_depth': 8, 'n_estimators': 51, 'subsample': 0.5611320996921224, 'colsample_bytree': 0.5115155737392881}. Best is trial 287 with value: 0.4880524518765835.\n",
            "[I 2024-11-26 00:14:41,496] Trial 294 finished with value: 0.5043575496867727 and parameters: {'eta': 0.09610397250335792, 'learning_rate': 0.013562681304588957, 'max_depth': 8, 'n_estimators': 61, 'subsample': 0.5369180146122748, 'colsample_bytree': 0.500743441704492}. Best is trial 287 with value: 0.4880524518765835.\n",
            "[I 2024-11-26 00:14:41,753] Trial 295 finished with value: 0.5076980109423735 and parameters: {'eta': 0.09514792422956361, 'learning_rate': 0.015113031696401817, 'max_depth': 8, 'n_estimators': 50, 'subsample': 0.5480507242221899, 'colsample_bytree': 0.5138416892349286}. Best is trial 287 with value: 0.4880524518765835.\n",
            "[I 2024-11-26 00:14:42,056] Trial 296 finished with value: 0.5989170983979749 and parameters: {'eta': 0.09977516906808004, 'learning_rate': 0.034562503294060035, 'max_depth': 8, 'n_estimators': 60, 'subsample': 0.5315334780449796, 'colsample_bytree': 0.5107275162556614}. Best is trial 287 with value: 0.4880524518765835.\n",
            "[I 2024-11-26 00:14:42,357] Trial 297 finished with value: 0.5035610194376876 and parameters: {'eta': 0.09732560489278877, 'learning_rate': 0.01252147131959541, 'max_depth': 8, 'n_estimators': 61, 'subsample': 0.5610597303734027, 'colsample_bytree': 0.5007366978235511}. Best is trial 287 with value: 0.4880524518765835.\n",
            "[I 2024-11-26 00:14:43,411] Trial 298 finished with value: 0.6171071032484148 and parameters: {'eta': 0.09662001299849497, 'learning_rate': 0.012907567007522646, 'max_depth': 8, 'n_estimators': 332, 'subsample': 0.5614534214725712, 'colsample_bytree': 0.5022010666889551}. Best is trial 287 with value: 0.4880524518765835.\n",
            "[I 2024-11-26 00:14:43,686] Trial 299 finished with value: 0.49838206846778627 and parameters: {'eta': 0.09464638326409452, 'learning_rate': 0.013790371782513609, 'max_depth': 8, 'n_estimators': 50, 'subsample': 0.5498003169973319, 'colsample_bytree': 0.5002348336119297}. Best is trial 287 with value: 0.4880524518765835.\n",
            "<ipython-input-7-33cffe80587d>:67: ExperimentalWarning: plot_optimization_history is experimental (supported from v2.2.0). The interface can change in the future.\n",
            "  optuna.visualization.matplotlib.plot_optimization_history(study)\n",
            "<ipython-input-7-33cffe80587d>:71: ExperimentalWarning: plot_param_importances is experimental (supported from v2.2.0). The interface can change in the future.\n",
            "  optuna.visualization.matplotlib.plot_param_importances(study)\n"
          ]
        }
      ],
      "source": [
        "# Se cargan los datos\n",
        "df = pd.read_csv('water_potability.csv')\n",
        "X, y = df.drop(\"Potability\", axis=1), df[\"Potability\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Configurar el directorio para los artefactos\n",
        "artifacts_dir = \"mlruns/artifacts\"\n",
        "os.makedirs(artifacts_dir, exist_ok=True)\n",
        "\n",
        "def optimize_model(trial):\n",
        "      params = {\n",
        "            \"objective\": \"binary:logistic\",\n",
        "            \"eval_metric\": \"logloss\",\n",
        "            \"eta\": trial.suggest_float('eta', 0.01, 0.1),\n",
        "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n",
        "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500),\n",
        "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
        "            }\n",
        "\n",
        "      # Se crea  el modelo\n",
        "      model = xgb.XGBClassifier(**params)\n",
        "\n",
        "      name_run = f\"XGBoost con lr {params['eta']}\"\n",
        "      # Registrar los resultados en MLflow\n",
        "      with mlflow.start_run(run_name = name_run):\n",
        "        # se entrena el modelo\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Se predice y calcula el f1\n",
        "        y_pred = model.predict(X_test)\n",
        "        valid_f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "\n",
        "        mlflow.log_params(params)\n",
        "        mlflow.log_metric(\"valid_f1\", valid_f1)\n",
        "\n",
        "      return valid_f1\n",
        "\n",
        "def main():\n",
        "    mlflow.set_experiment(\"XGBoost Potability Experiment\")\n",
        "\n",
        "    # Se crea un estudio de Optuna\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(optimize_model, n_trials=300)\n",
        "\n",
        "    best_trial = study.best_trial\n",
        "\n",
        "    # Guardar el mejor modelo\n",
        "    models_dir = \"models\"\n",
        "    os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "    best_params = best_trial.params\n",
        "    best_model = xgb.XGBClassifier(**best_params)\n",
        "    best_model.fit(X_train, y_train)\n",
        "\n",
        "    model_path = \"models/best_model.pkl\"\n",
        "    with open(model_path, 'wb') as f:\n",
        "        pickle.dump(best_model, f)\n",
        "    mlflow.log_artifact('models/best_model.pkl')\n",
        "\n",
        "    # Guardar gráficos de Optuna\n",
        "    plots_dir = \"plots\"\n",
        "    os.makedirs(plots_dir, exist_ok=True)\n",
        "\n",
        "    optuna.visualization.matplotlib.plot_optimization_history(study)\n",
        "    plt.savefig(f\"{plots_dir}/optimization_history.png\")\n",
        "    plt.close()\n",
        "\n",
        "    optuna.visualization.matplotlib.plot_param_importances(study)\n",
        "    plt.savefig(f\"{plots_dir}/param_importance.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Loggear gráficos en MLflow\n",
        "    mlflow.log_artifact(f\"{plots_dir}/optimization_history.png\")\n",
        "    mlflow.log_artifact(f\"{plots_dir}/param_importance.png\")\n",
        "\n",
        "    # Guardar la importancia de características\n",
        "    xgb.plot_importance(best_model, importance_type=\"weight\")\n",
        "    plt.savefig(f\"{artifacts_dir}/feature_importance.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Registrar las versiones de las librerías\n",
        "    mlflow.log_artifacts(artifacts_dir)\n",
        "    mlflow.set_tag(\"mlflow.version\", mlflow.__version__)\n",
        "    mlflow.set_tag(\"optuna.version\", optuna.__version__)\n",
        "    mlflow.set_tag(\"xgboost.version\", xgb.__version__)\n",
        "\n",
        "    return best_model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    best_model = main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.end_run()"
      ],
      "metadata": {
        "id": "__Y4QV1tLH5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL2iG18289j9"
      },
      "source": [
        "# **2. FastAPI (2.0 puntos)**\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://media3.giphy.com/media/YQitE4YNQNahy/giphy-downsized-large.gif\" width=\"500\">\n",
        "</div>\n",
        "\n",
        "Con el modelo ya entrenado, la idea de esta sección es generar una API REST a la cual se le pueda hacer *requests* para así interactuar con su modelo. En particular, se le pide:\n",
        "\n",
        "- Guardar el código de esta sección en el archivo `main.py`. Note que ejecutar `python main.py` debería levantar el servidor en el puerto por defecto.\n",
        "- Defina `GET` con ruta tipo *home* que describa brevemente su modelo, el problema que intenta resolver, su entrada y salida.\n",
        "- Defina un `POST` a la ruta `/potabilidad/` donde utilice su mejor optimizado para predecir si una medición de agua es o no potable. Por ejemplo, una llamada de esta ruta con un *body*:\n",
        "\n",
        "```json\n",
        "{\n",
        "   \"ph\":10.316400384553162,\n",
        "   \"Hardness\":217.2668424334475,\n",
        "   \"Solids\":10676.508475429378,\n",
        "   \"Chloramines\":3.445514571005745,\n",
        "   \"Sulfate\":397.7549459751925,\n",
        "   \"Conductivity\":492.20647361771086,\n",
        "   \"Organic_carbon\":12.812732207582542,\n",
        "   \"Trihalomethanes\":72.28192021570328,\n",
        "   \"Turbidity\":3.4073494284238364\n",
        "}\n",
        "```\n",
        "\n",
        "Su servidor debería retornar una respuesta HTML con código 200 con:\n",
        "\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"potabilidad\": 0 # respuesta puede variar según el clasificador que entrenen\n",
        "}\n",
        "```\n",
        "\n",
        "**`HINT:` Recuerde que puede utilizar [http://localhost:8000/docs](http://localhost:8000/docs) para hacer un `POST`.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"fastapi[all]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j924lyNs_Y5E",
        "outputId": "9f05f3ed-d122-4870-f197-8ce31d431257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi[all]\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi[all])\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi[all]) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi[all]) (4.12.2)\n",
            "Collecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all])\n",
            "  Downloading fastapi_cli-0.0.5-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi[all]) (0.27.2)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi[all]) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi[all])\n",
            "  Downloading python_multipart-0.0.17-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: itsdangerous>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from fastapi[all]) (2.2.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from fastapi[all]) (6.0.2)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi[all])\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: orjson>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from fastapi[all]) (3.10.11)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[all])\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all])\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pydantic-settings>=2.0.0 (from fastapi[all])\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting pydantic-extra-types>=2.0.0 (from fastapi[all])\n",
            "  Downloading pydantic_extra_types-2.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[all])\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email-validator>=2.0.0->fastapi[all]) (3.10)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (0.13.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi[all]) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi[all]) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi[all]) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi[all]) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[all]) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi[all]) (3.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[all]) (2.23.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.0.0->fastapi[all])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.12.0->uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all]) (8.1.7)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all])\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all])\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all])\n",
            "  Downloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all])\n",
            "  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->fastapi[all]) (1.2.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (0.1.2)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi_cli-0.0.5-py3-none-any.whl (9.5 kB)\n",
            "Downloading pydantic_extra_types-2.10.0-py3-none-any.whl (34 kB)\n",
            "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading python_multipart-0.0.17-py3-none-any.whl (24 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.6/442.6 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets, uvloop, uvicorn, ujson, python-multipart, python-dotenv, httptools, dnspython, watchfiles, starlette, email-validator, pydantic-settings, pydantic-extra-types, fastapi, fastapi-cli\n",
            "Successfully installed dnspython-2.7.0 email-validator-2.2.0 fastapi-0.115.5 fastapi-cli-0.0.5 httptools-0.6.4 pydantic-extra-types-2.10.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 python-multipart-0.0.17 starlette-0.41.3 ujson-5.10.0 uvicorn-0.32.1 uvloop-0.21.0 watchfiles-1.0.0 websockets-14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class WaterPotability(BaseModel):\n",
        "    ph: float\n",
        "    Hardness: float\n",
        "    Solids: float\n",
        "    Chloramines: float\n",
        "    Sulfate: float\n",
        "    Conductivity: float\n",
        "    Organic_carbon: float\n",
        "    Trihalomethanes: float\n",
        "    Turbidity: float"
      ],
      "metadata": {
        "id": "MfqmevAyH87d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, HTTPException\n",
        "from fastapi.responses import HTMLResponse\n",
        "from utils import WaterPotability\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "\n",
        "# inicializamos API\n",
        "app = FastAPI()\n",
        "\n",
        "# Se define ruta del mejor modelo y se carga\n",
        "PATH_BEST_MODEL = \"models/best_model.pkl\"\n",
        "with open(PATH_BEST_MODEL, 'rb') as f:\n",
        "    best_model = pickle.load(f)\n",
        "\n",
        "# Defina GET con ruta tipo home que describa brevemente su modelo, \\\n",
        "# el problema que intenta resolver, su entrada y salida.\n",
        "@app.get('/', response_class=HTMLResponse) # ruta\n",
        "async def home():\n",
        "    html_response = \"\"\"\n",
        "   <html>\n",
        "    <h1>Modelo de Machine Learning para predecir la calidad del agua</h1>\n",
        "    <p>Este modelo de Machine Learning se encarga de predecir la calidad del agua en base a diferentes features.</p>\n",
        "\n",
        "    <body>\n",
        "        <p> Ejemplo de entrada del modelo: </p>\n",
        "\n",
        "    <p style=\"text-align: center;\">\n",
        "            \"ph\":10.316400384553162, <br>\n",
        "            \"Hardness\":217.2668424334475, <br>\n",
        "            \"Solids\":10676.508475429378, <br>\n",
        "            \"Chloramines\":3.445514571005745, <br>\n",
        "            \"Sulfate\":397.7549459751925, <br>\n",
        "            \"Conductivity\":492.20647361771086, <br>\n",
        "            \"Organic_carbon\":12.812732207582542, <br>\n",
        "            \"Trihalomethanes\":72.28192021570328, <br>\n",
        "            \"Turbidity\":3.4073494284238364 <br>\n",
        "    </p>\n",
        "\n",
        "    <p> Ejemplo de salida del modelo: </p>\n",
        "    <p style=\"text-align: center;\"> \"potabilidad\": 0 </p>\n",
        "     </body>\n",
        "    </html>\n",
        "\"\"\"\n",
        "    return html_response\n",
        "\n",
        "\n",
        "@app.post('/predict') # ruta\n",
        "async def predict(data: WaterPotability):\n",
        "    features = [data.ph, data.Hardness, data.Solids, data.Chloramines, data.Sulfate, \\\n",
        "        data.Conductivity, data.Organic_carbon, data.Trihalomethanes, data.Turbidity]\n",
        "\n",
        "    # se realiza la predicción\n",
        "    prediction = best_model.predict([features])\n",
        "\n",
        "    html_content = f\"\"\"\n",
        "    <html>\n",
        "    <h1>Resultado de la predicción</h1>\n",
        "    <p>El modelo predice que la calidad del agua es: {prediction[0]}</p>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "    return HTMLResponse(content=html_content, status_code=200)"
      ],
      "metadata": {
        "id": "383DYHV8HyDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSausqDJ9CQh"
      },
      "source": [
        "# **3. Docker (2 puntos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNmC483flS00"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/1*9rafh2W0rbRJIKJzqYc8yA.gif\" width=\"500\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niMA_qsCjqlv"
      },
      "source": [
        "Tras el éxito de su aplicación web para generar la salida, Smapina le solicita que genere un contenedor para poder ejecutarla en cualquier computador de la empresa de agua potable.\n",
        "\n",
        "## **3.1 Creación de Container (1 punto)**\n",
        "\n",
        "Cree un Dockerfile que use una imagen base de Python, copie los archivos del proyecto e instale las dependencias desde un `requirements.txt`. Con esto, construya y ejecute el contenedor Docker para la API configurada anteriormente. Entregue el código fuente (incluyendo `main.py`, `requirements.txt`, y `Dockerfile`) y la imagen Docker de la aplicación. Para la dockerización, asegúrese de cumplir con los siguientes puntos:\n",
        "\n",
        "1. **Generar un archivo `.dockerignore`** que ignore carpetas y archivos innecesarios dentro del contenedor.\n",
        "2. **Configurar un volumen** que permita la persistencia de los datos en una ruta local del computador.\n",
        "3. **Exponer el puerto** para acceder a la ruta de la API sin tener que entrar al contenedor directamente.\n",
        "4. **Incluir imágenes en el notebook** que muestren la ejecución del contenedor y los resultados obtenidos.\n",
        "5. **Revisar y comentar los recursos utilizados por el contenedor**. Analice si los contenedores son livianos en términos de recursos.\n",
        "\n",
        "\n",
        "- Respuestas:\n",
        "\n",
        "4. Se agregan las imágenes de la ejecución del contenedor junto con predicciones para el ejemplo (y su resultado) (docker.jpg) y los recursos que utiliza (usage.png)\n",
        "\n",
        "5. Al ver el uso que se le da, se puede notar que este tipo de contenedor es bastante liviano ya que no utiliza tantos recursos (como CPU, RAM) debido a la naturaleza de este, ya que simplemente es una API con un modelo liviano.\n",
        "\n",
        "\n",
        "## **3.2 Preguntas de Smapina (1 punto)**\n",
        "Tras haber experimentado con Docker, Smapina desea profundizar más en el tema y decide realizarle las siguientes consultas:\n",
        "\n",
        "- ¿Cómo se diferencia Docker de una máquina virtual (VM)?\n",
        "\n",
        "Si bien ambas son tecnologías de virtualización, se diferencian en la forma en que gestionan los recursos. Las VM ejecutan un sistema operativo completo (como Linux, Windows, MacOS, etc) en un hipervisor. Por otro lado, Docker utiliza contenedores que permite que las aplicaciones se ejecuten de manera aislada pero compartiendo el mismo kernel del sistema operativo anfitrión. Esto hace que Docker sea más ligero, más rápido de iniciar y menos demandante en recursos.\n",
        "\n",
        "\n",
        "- ¿Cuál es la diferencia entre usar Docker y ejecutar la aplicación directamente en el sistema local?\n",
        "\n",
        "Cuando se ejecuta una aplicación directamente en el sistema local, hay una dependencia de las configuraciones espécificas del entorno, lo que podría causar inconsistencias al mover la aplicación a otro sistema. En cambio, Docker encapsula la aplicación con todas sus dependencias en un contenedor, asegurando que se ejctue igual en cualquier máquina con Docker instalado.\n",
        "\n",
        "\n",
        "- ¿Cómo asegura Docker la consistencia entre diferentes entornos de desarrollo y producción?\n",
        "\n",
        "Docker asegura la consistencia entre distintos entornos mediante la creación de imagenes de contenedor. Al ejecutar la misma imagen en desarrollo y producción, se garantiza que el comportamiento sea idéntico, independiente de las diferencias en los sistemas subyacentes.\n",
        "\n",
        "\n",
        "- ¿Cómo se gestionan los volúmenes en Docker para la persistencia de datos?\n",
        "\n",
        "Los volúmenes en Docker son utilizados para persistir datos generados y utilizados por contenedores, estos son directorios montados desde el sistema host o son volúmenes administrados por Docker. Con esto, se garantiza que los datos no se pierdan cuando un contenedor se elimina o se recrea.\n",
        "\n",
        "- ¿Qué son Dockerfile y docker-compose.yml, y cuál es su propósito?\n",
        "\n",
        "Un Dockerfile es un archivo de texto que define los pasos para crear una imagen de Docker, especificando el sistema base, las dependencias y configuraciones necesarias para ejecutar la aplicación. Su propósito es automatizar y estandarizar el proceso de construcción de imágenes Docker. Por otro lado, un docker-compose.yml es un archivo de configuración utilizado por Docker Compose para definir y ejecutar aplicaciones multicontenedor. Este archivo describe los servicios, redes y volúmenes necesarios para la aplicación, lo que permite orquestar fácilmente múltiples contenedores y gestionar sus interacciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xJ_ZK1IfnZW"
      },
      "source": [
        "# Conclusión\n",
        "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://i.pinimg.com/originals/84/5d/f1/845df1aefc6a5e37ae575327a0cc6e43.gif\" width=\"500\">\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}